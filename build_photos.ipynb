{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825b12a-386c-4546-963e-f90500281dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Prerequisites - all files in their album folders are located inside images/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab3c4119-d6a1-4ccd-9849-cb6541bd0524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–ª—å–±–æ–º–∞–º:\n",
      "\n",
      "üìÅ PhotoMap 2010-2013:\n",
      "  json: 258\n",
      "  .jpg: 257\n",
      "  edited: 14\n",
      "\n",
      "üìÅ PhotoMap 2014-2016:\n",
      "  json: 382\n",
      "  edited: 76\n",
      "  .jpg: 381\n",
      "\n",
      "üìÅ PhotoMap 2019-2021:\n",
      "  .jpg: 782\n",
      "  json: 785\n",
      "  other: 2\n",
      "  edited: 58\n",
      "\n",
      "üìÅ PhotoMap 2022-2025:\n",
      "  json: 654\n",
      "  .jpg: 627\n",
      "  edited: 7\n",
      "  .heic: 6\n",
      "  .jpeg: 20\n",
      "\n",
      "üìÅ PhotoMap 08-09:\n",
      "  .jpg: 109\n",
      "  json: 110\n",
      "  edited: 83\n",
      "\n",
      "üìÅ PhotoMap 2017-2019:\n",
      "  json: 250\n",
      "  .jpg: 249\n",
      "  edited: 5\n",
      "\n",
      "üìà –ò—Ç–æ–≥–æ –ø–æ –≤—Å–µ–º –∞–ª—å–±–æ–º–∞–º:\n",
      "  json: 2439\n",
      "  .jpg: 2405\n",
      "  edited: 243\n",
      "  other: 2\n",
      "  .heic: 6\n",
      "  .jpeg: 20\n",
      "\n",
      "üßÆ –í—Å–µ–≥–æ —Ñ–æ—Ç–æ-—Ñ–∞–π–ª–æ–≤ (–±–µ–∑ -edited): 2431\n",
      "‚úÇÔ∏è  –§–∞–π–ª–æ–≤ —Å '-edited' –≤ –∏–º–µ–Ω–∏:        243\n",
      "‚úÖ –ì–æ–¥–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤:        2431\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# === –ü–∞–ø–∫–∞ —Å –∞–ª—å–±–æ–º–∞–º–∏ ===\n",
    "ROOT_DIR = \"images\"\n",
    "album_dirs = [d for d in os.listdir(ROOT_DIR) if os.path.isdir(os.path.join(ROOT_DIR, d))]\n",
    "\n",
    "# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á—ë—Ç—á–∏–∫–æ–≤ ===\n",
    "stats = {}\n",
    "total = defaultdict(int)\n",
    "\n",
    "# === –®–∞–±–ª–æ–Ω—ã ===\n",
    "pattern_copy = re.compile(r\"\\s\\(\\d+\\)| copy\", re.IGNORECASE)\n",
    "\n",
    "# === –ê–Ω–∞–ª–∏–∑ –ø–æ –∞–ª—å–±–æ–º–∞–º ===\n",
    "for album in album_dirs:\n",
    "    folder_path = os.path.join(ROOT_DIR, album)\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "\n",
    "        ext = os.path.splitext(file)[1].lower()\n",
    "\n",
    "        if ext in ['.jpg', '.jpeg', '.heic']:\n",
    "            if '-edited' in file.lower():\n",
    "                counts['edited'] += 1\n",
    "            else:\n",
    "                counts[ext] += 1\n",
    "                if pattern_copy.search(file):\n",
    "                    counts['renamed'] += 1\n",
    "        elif ext == '.json':\n",
    "            counts['json'] += 1\n",
    "        else:\n",
    "            counts['other'] += 1\n",
    "\n",
    "    stats[album] = dict(counts)\n",
    "    for k, v in counts.items():\n",
    "        total[k] += v\n",
    "\n",
    "# === –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===\n",
    "print(\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–ª—å–±–æ–º–∞–º:\")\n",
    "for album, counts in stats.items():\n",
    "    print(f\"\\nüìÅ {album}:\")\n",
    "    for k, v in counts.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "# === –ü–æ–¥—Å—á—ë—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–≥–æ–¥–Ω—ã—Ö —Ñ–æ—Ç–æ ===\n",
    "photo_exts = ['.jpg', '.jpeg', '.heic']\n",
    "total_photos = sum(total[ext] for ext in photo_exts)\n",
    "total_edited = total['edited']\n",
    "usable_photos = total_photos  # editable —É–∂–µ –∏—Å–∫–ª—é—á–µ–Ω—ã –≤—ã—à–µ, –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è\n",
    "\n",
    "print(\"\\nüìà –ò—Ç–æ–≥–æ –ø–æ –≤—Å–µ–º –∞–ª—å–±–æ–º–∞–º:\")\n",
    "for k, v in total.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"\\nüßÆ –í—Å–µ–≥–æ —Ñ–æ—Ç–æ-—Ñ–∞–π–ª–æ–≤ (–±–µ–∑ -edited): {total_photos}\")\n",
    "print(f\"‚úÇÔ∏è  –§–∞–π–ª–æ–≤ —Å '-edited' –≤ –∏–º–µ–Ω–∏:        {total_edited}\")\n",
    "print(f\"‚úÖ –ì–æ–¥–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤:        {usable_photos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d4120426-21f5-4cff-90d9-9a426e16e5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí images/PhotoMap 2010-2013/IMG_4498.JPG\n",
      "[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí images/PhotoMap 2010-2013/IMG_0513.JPG\n",
      "[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí images/PhotoMap 2010-2013/IMG_0924.JPG\n",
      "[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí images/PhotoMap 08-09/IMG_1192.jpg\n",
      "[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí images/PhotoMap 08-09/IMG_0529.JPG\n",
      "[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí images/PhotoMap 08-09/IMG_0532.JPG\n",
      "[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí images/PhotoMap 08-09/IMG_0533.JPG\n",
      "\n",
      "üìä –°–≤–æ–¥–∫–∞:\n",
      "üßÆ –í—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ (–±–µ–∑ edited): 2431\n",
      "‚úÖ –° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: 2424\n",
      "üö´ –ë–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:  7\n",
      "üì¶ –£—á—Ç–µ–Ω–æ –≤—Å–µ–≥–æ:   2431\n",
      "‚ùó –ü—Ä–æ–ø—É—â–µ–Ω–æ:      0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "from datetime import datetime\n",
    "\n",
    "# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ===\n",
    "IMAGES_FOLDER = \"images\"\n",
    "OUT_FOLDER = \"csv\"\n",
    "MISSING_FOLDER = \"csv\"\n",
    "\n",
    "os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(MISSING_FOLDER, exist_ok=True)\n",
    "\n",
    "photos_output_path = os.path.join(OUT_FOLDER, \"photos.csv\")\n",
    "missing_output_path = os.path.join(MISSING_FOLDER, \"missing_coords.csv\")\n",
    "\n",
    "def extract_gps_from_exif(image_path):\n",
    "    # –ü—Ä–æ–±—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è JPG, –Ω–µ –¥–ª—è HEIC\n",
    "    if not image_path.lower().endswith(('.jpg', '.jpeg')):\n",
    "        return None, None\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        exif_data = image._getexif()\n",
    "        if not exif_data:\n",
    "            return None, None\n",
    "\n",
    "        gps_info = {}\n",
    "        date_str = None\n",
    "\n",
    "        for tag, value in exif_data.items():\n",
    "            decoded = TAGS.get(tag)\n",
    "            if decoded == \"GPSInfo\":\n",
    "                for t in value:\n",
    "                    sub_decoded = GPSTAGS.get(t)\n",
    "                    gps_info[sub_decoded] = value[t]\n",
    "            elif decoded == \"DateTimeOriginal\":\n",
    "                date_str = value\n",
    "\n",
    "        def convert_to_degrees(value):\n",
    "            d, m, s = value\n",
    "            return float(d) + float(m)/60 + float(s)/3600\n",
    "\n",
    "        if not gps_info:\n",
    "            return None, date_str\n",
    "\n",
    "        lat = convert_to_degrees(gps_info.get(\"GPSLatitude\"))\n",
    "        if gps_info.get(\"GPSLatitudeRef\") == \"S\":\n",
    "            lat = -lat\n",
    "\n",
    "        lon = convert_to_degrees(gps_info.get(\"GPSLongitude\"))\n",
    "        if gps_info.get(\"GPSLongitudeRef\") == \"W\":\n",
    "            lon = -lon\n",
    "\n",
    "        return (lat, lon), date_str\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def extract_gps_from_json(json_path):\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            geo = data.get(\"geoData\")\n",
    "            photo_taken_time = data.get(\"photoTakenTime\", {}).get(\"timestamp\")\n",
    "            if geo:\n",
    "                lat = geo.get(\"latitude\")\n",
    "                lon = geo.get(\"longitude\")\n",
    "                return (lat, lon), photo_taken_time\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def find_json_path_for_image(image_path):\n",
    "    base = os.path.basename(image_path)\n",
    "    folder = os.path.dirname(image_path)\n",
    "\n",
    "    suffixes = [\n",
    "        \".supplemental-metadata.json\",\n",
    "        \".supplemental-meta.json\",\n",
    "        \".supplemental-metada.json\",\n",
    "        \".supplemental-metadat.json\",\n",
    "        \".supplemental-me.json\"\n",
    "    ]\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        candidate = image_path + suffix\n",
    "        if os.path.exists(candidate):\n",
    "            return candidate\n",
    "\n",
    "    match = re.match(r'^(.*)\\((\\d+)\\)\\.(jpg|jpeg|heic)$', base, re.IGNORECASE)\n",
    "    if match:\n",
    "        base_clean = match.group(1).strip()\n",
    "        suffix_num = match.group(2)\n",
    "        ext = match.group(3)\n",
    "        for sfx in suffixes:\n",
    "            sfx_with_index = sfx.replace(\".json\", f\"({suffix_num}).json\")\n",
    "            alt_json = os.path.join(folder, f\"{base_clean}.{ext}{sfx_with_index}\")\n",
    "            if os.path.exists(alt_json):\n",
    "                return alt_json\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_date_components(date_str):\n",
    "    try:\n",
    "        if date_str and len(str(date_str)) == 10 and str(date_str).isdigit():\n",
    "            dt = datetime.fromtimestamp(int(date_str))\n",
    "        else:\n",
    "            dt = datetime.strptime(date_str, \"%Y:%m:%d %H:%M:%S\")\n",
    "        return dt.year, dt.month, dt.day\n",
    "    except:\n",
    "        return None, None, None\n",
    "\n",
    "def process_images(image_folder, output_file, missing_file):\n",
    "    photo_records = []\n",
    "    missing_records = []\n",
    "    total_processed = 0\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(image_folder):\n",
    "        for file in filenames:\n",
    "            if not file.lower().endswith(('.jpg', '.jpeg', '.heic')):\n",
    "                continue\n",
    "            if '-edited' in file.lower() or '_edited' in file.lower():\n",
    "                continue\n",
    "\n",
    "            fname = os.path.join(dirpath, file)\n",
    "            base_name = os.path.basename(fname)\n",
    "            source_type = None\n",
    "            total_processed += 1\n",
    "\n",
    "            try:\n",
    "                gps, date_str = extract_gps_from_exif(fname)\n",
    "                source_type = \"exif\"\n",
    "\n",
    "                if not gps:\n",
    "                    json_path = find_json_path_for_image(fname)\n",
    "                    if json_path:\n",
    "                        gps, json_date = extract_gps_from_json(json_path)\n",
    "                        source_type = \"json\"\n",
    "                        if not date_str and json_date:\n",
    "                            date_str = json_date\n",
    "\n",
    "                lat, lon = gps if gps else (None, None)\n",
    "                year, month, day = parse_date_components(date_str) if date_str else (None, None, None)\n",
    "\n",
    "                if lat == 0.0 and lon == 0.0:\n",
    "                    print(f\"[!] –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã 0.0/0.0 ‚Üí {fname}\")\n",
    "                    raise ValueError(\"zero-coordinates\")\n",
    "\n",
    "                if lat is not None and lon is not None:\n",
    "                    row = {\n",
    "                        'filename': base_name,\n",
    "                        'folder': os.path.basename(OUT_FOLDER),\n",
    "                        'latitude': lat,\n",
    "                        'longitude': lon,\n",
    "                        'year': year,\n",
    "                        'month': month,\n",
    "                        'day': day,\n",
    "                        'source_path': fname,\n",
    "                        'source_type': source_type\n",
    "                    }\n",
    "                    photo_records.append(row)\n",
    "                else:\n",
    "                    raise ValueError(\"no-coordinates\")\n",
    "\n",
    "            except Exception as e:\n",
    "                missing_records.append({\n",
    "                    'filename': base_name,\n",
    "                    'folder': os.path.basename(MISSING_FOLDER),\n",
    "                    'latitude': None,\n",
    "                    'longitude': None,\n",
    "                    'year': None,\n",
    "                    'month': None,\n",
    "                    'day': None,\n",
    "                    'error': str(e),\n",
    "                    'source_path': fname,\n",
    "                    'source_type': None\n",
    "                })\n",
    "\n",
    "    # –ó–∞–ø–∏—Å—å CSV\n",
    "    photo_fields = ['filename', 'folder', 'latitude', 'longitude', 'year', 'month', 'day', 'source_path', 'source_type']\n",
    "    missing_fields = photo_fields + ['error']\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=photo_fields)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(photo_records)\n",
    "\n",
    "    with open(missing_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=missing_fields)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(missing_records)\n",
    "\n",
    "    # üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞\n",
    "    print(\"\\nüìä –°–≤–æ–¥–∫–∞:\")\n",
    "    print(f\"üßÆ –í—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ (–±–µ–∑ edited): {total_processed}\")\n",
    "    print(f\"‚úÖ –° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: {len(photo_records)}\")\n",
    "    print(f\"üö´ –ë–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:  {len(missing_records)}\")\n",
    "    print(f\"üì¶ –£—á—Ç–µ–Ω–æ –≤—Å–µ–≥–æ:   {len(photo_records) + len(missing_records)}\")\n",
    "    print(f\"‚ùó –ü—Ä–æ–ø—É—â–µ–Ω–æ:      {total_processed - (len(photo_records) + len(missing_records))}\")\n",
    "\n",
    "# === –ó–∞–ø—É—Å–∫ ===\n",
    "process_images(IMAGES_FOLDER, photos_output_path, missing_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bbfaef-9582-445d-912b-fc54bd8f93c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
