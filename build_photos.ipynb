{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825b12a-386c-4546-963e-f90500281dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Prerequisites - all files in their album folders are located inside images/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c4119-d6a1-4ccd-9849-cb6541bd0524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# === –ü–∞–ø–∫–∞ —Å –∞–ª—å–±–æ–º–∞–º–∏ ===\n",
    "ROOT_DIR = \"images\"\n",
    "album_dirs = [d for d in os.listdir(ROOT_DIR) if os.path.isdir(os.path.join(ROOT_DIR, d))]\n",
    "\n",
    "# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á—ë—Ç—á–∏–∫–æ–≤ ===\n",
    "stats = {}\n",
    "total = defaultdict(int)\n",
    "\n",
    "# === –®–∞–±–ª–æ–Ω—ã ===\n",
    "pattern_copy = re.compile(r\"\\s\\(\\d+\\)| copy\", re.IGNORECASE)\n",
    "\n",
    "# === –ê–Ω–∞–ª–∏–∑ –ø–æ –∞–ª—å–±–æ–º–∞–º ===\n",
    "for album in album_dirs:\n",
    "    folder_path = os.path.join(ROOT_DIR, album)\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "\n",
    "        ext = os.path.splitext(file)[1].lower()\n",
    "\n",
    "        if ext in ['.jpg', '.jpeg', '.heic']:\n",
    "            if '-edited' in file.lower():\n",
    "                counts['edited'] += 1\n",
    "            else:\n",
    "                counts[ext] += 1\n",
    "                if pattern_copy.search(file):\n",
    "                    counts['renamed'] += 1\n",
    "        elif ext == '.json':\n",
    "            counts['json'] += 1\n",
    "        else:\n",
    "            counts['other'] += 1\n",
    "\n",
    "    stats[album] = dict(counts)\n",
    "    for k, v in counts.items():\n",
    "        total[k] += v\n",
    "\n",
    "# === –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===\n",
    "print(\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–ª—å–±–æ–º–∞–º:\")\n",
    "for album, counts in stats.items():\n",
    "    print(f\"\\nüìÅ {album}:\")\n",
    "    for k, v in counts.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "# === –ü–æ–¥—Å—á—ë—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–≥–æ–¥–Ω—ã—Ö —Ñ–æ—Ç–æ ===\n",
    "photo_exts = ['.jpg', '.jpeg', '.heic']\n",
    "total_photos = sum(total[ext] for ext in photo_exts)\n",
    "total_edited = total['edited']\n",
    "usable_photos = total_photos  # editable —É–∂–µ –∏—Å–∫–ª—é—á–µ–Ω—ã –≤—ã—à–µ, –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è\n",
    "\n",
    "print(\"\\nüìà –ò—Ç–æ–≥–æ –ø–æ –≤—Å–µ–º –∞–ª—å–±–æ–º–∞–º:\")\n",
    "for k, v in total.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"\\nüßÆ –í—Å–µ–≥–æ —Ñ–æ—Ç–æ-—Ñ–∞–π–ª–æ–≤ (–±–µ–∑ -edited): {total_photos}\")\n",
    "print(f\"‚úÇÔ∏è  –§–∞–π–ª–æ–≤ —Å '-edited' –≤ –∏–º–µ–Ω–∏:        {total_edited}\")\n",
    "print(f\"‚úÖ –ì–æ–¥–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤:        {usable_photos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0bb1b-bf33-46e5-aafd-e23734cadb94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from PIL import Image, ExifTags\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "ROOT = os.path.abspath(\".\")\n",
    "SRC_FOLDER = os.path.join(ROOT, \"images/PhotoMap 2022-2025\")\n",
    "OUT_FOLDER = os.path.join(ROOT, \"photos\")\n",
    "CSV_FOLDER = os.path.join(ROOT, \"csv\")\n",
    "CSV_MAIN = os.path.join(CSV_FOLDER, \"photos.csv\")\n",
    "CSV_MISSING = os.path.join(CSV_FOLDER, \"missing_coords.csv\")\n",
    "\n",
    "os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "# === Helpers ===\n",
    "def convert_to_degrees(v):\n",
    "    d, m, s = v\n",
    "    return float(d) + float(m) / 60 + float(s) / 3600\n",
    "\n",
    "def extract_gps_from_exif(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        exif_data = image._getexif()\n",
    "        if not exif_data:\n",
    "            return None, None\n",
    "\n",
    "        gps_info = {}\n",
    "        date_str = None\n",
    "        for tag, value in exif_data.items():\n",
    "            decoded = ExifTags.TAGS.get(tag)\n",
    "            if decoded == \"GPSInfo\":\n",
    "                for t in value:\n",
    "                    sub_decoded = ExifTags.GPSTAGS.get(t)\n",
    "                    gps_info[sub_decoded] = value[t]\n",
    "            elif decoded == \"DateTimeOriginal\":\n",
    "                date_str = value\n",
    "\n",
    "        if not gps_info:\n",
    "            return None, date_str\n",
    "\n",
    "        lat = convert_to_degrees(gps_info.get(\"GPSLatitude\"))\n",
    "        if gps_info.get(\"GPSLatitudeRef\") == \"S\":\n",
    "            lat = -lat\n",
    "        lon = convert_to_degrees(gps_info.get(\"GPSLongitude\"))\n",
    "        if gps_info.get(\"GPSLongitudeRef\") == \"W\":\n",
    "            lon = -lon\n",
    "\n",
    "        return (lat, lon), date_str\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def extract_gps_from_json(json_path):\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            geo = data.get(\"geoData\")\n",
    "            photo_taken_time = data.get(\"photoTakenTime\", {}).get(\"timestamp\")\n",
    "            if geo:\n",
    "                lat = geo.get(\"latitude\")\n",
    "                lon = geo.get(\"longitude\")\n",
    "                return (lat, lon), photo_taken_time\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def find_json_path_for_image(image_path):\n",
    "    base = os.path.basename(image_path)\n",
    "    folder = os.path.dirname(image_path)\n",
    "\n",
    "    suffixes = [\n",
    "        \".supplemental-metadata.json\",\n",
    "        \".supplemental-meta.json\",\n",
    "        \".supplemental-metada.json\",\n",
    "        \".supplemental-metadat.json\",\n",
    "        \".supplemental-me.json\"\n",
    "    ]\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        candidate = image_path + suffix\n",
    "        if os.path.exists(candidate):\n",
    "            return candidate\n",
    "\n",
    "    match = re.match(r'^(.*)\\((\\d+)\\)\\.(jpg|jpeg|heic)$', base, re.IGNORECASE)\n",
    "    if match:\n",
    "        base_clean = match.group(1).strip()\n",
    "        suffix_num = match.group(2)\n",
    "        ext = match.group(3)\n",
    "        for sfx in suffixes:\n",
    "            sfx_with_index = sfx.replace(\".json\", f\"({suffix_num}).json\")\n",
    "            alt_json = os.path.join(folder, f\"{base_clean}.{ext}{sfx_with_index}\")\n",
    "            if os.path.exists(alt_json):\n",
    "                return alt_json\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_date_components(date_str):\n",
    "    try:\n",
    "        if date_str and len(str(date_str)) == 10 and str(date_str).isdigit():\n",
    "            dt = datetime.fromtimestamp(int(date_str))\n",
    "        else:\n",
    "            dt = datetime.strptime(date_str, \"%Y:%m:%d %H:%M:%S\")\n",
    "        return str(dt.year), f\"{dt.month:02d}\", f\"{dt.day:02d}\"\n",
    "    except:\n",
    "        return \"2099\", \"01\", \"01\"\n",
    "\n",
    "def spiral_coords(lat, lon, index, step=0.0002):\n",
    "    angle = index * (math.pi / 3)\n",
    "    radius = step * (1 + index // 6)\n",
    "    return lat + radius * math.cos(angle), lon + radius * math.sin(angle)\n",
    "\n",
    "# === Find all images ===\n",
    "image_files = []\n",
    "for dirpath, _, filenames in os.walk(SRC_FOLDER):\n",
    "    for f in filenames:\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.heic')) and \"-edited\" not in f.lower():\n",
    "            image_files.append(os.path.join(dirpath, f))\n",
    "\n",
    "# === Processing ===\n",
    "Image.init()\n",
    "coords_seen = {}\n",
    "records_ok = []\n",
    "records_missing = []\n",
    "\n",
    "for in_path in tqdm(image_files, desc=\"\\U0001f4e6 –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\", ncols=80):\n",
    "    source_filename = os.path.basename(in_path)\n",
    "    ext = os.path.splitext(source_filename)[1].lower()\n",
    "    album = os.path.basename(os.path.dirname(in_path))\n",
    "\n",
    "    try:\n",
    "        image = Image.new(\"RGB\", (1, 1), (255, 255, 255))\n",
    "\n",
    "        lat, lon, date_str = None, None, None\n",
    "        source_type = None\n",
    "\n",
    "        if ext in [\".jpg\", \".jpeg\"]:\n",
    "            gps, date_str = extract_gps_from_exif(in_path)\n",
    "            if gps:\n",
    "                lat, lon = gps\n",
    "                source_type = \"exif\"\n",
    "\n",
    "        if lat is None or lon is None:\n",
    "            json_path = find_json_path_for_image(in_path)\n",
    "            if json_path:\n",
    "                gps_json, json_date = extract_gps_from_json(json_path)\n",
    "                if gps_json is not None:\n",
    "                    try:\n",
    "                        lat = float(gps_json[0])\n",
    "                        lon = float(gps_json[1])\n",
    "                        source_type = \"json\"\n",
    "                    except:\n",
    "                        lat, lon = None, None\n",
    "                if not date_str and json_date:\n",
    "                    date_str = json_date\n",
    "\n",
    "        year, month, day = parse_date_components(date_str)\n",
    "        base_name = f\"IMG_{year}{month}{day}_{abs(hash(source_filename)) % 10**6}.jpg\"\n",
    "        out_path = os.path.join(OUT_FOLDER, base_name)\n",
    "        image.save(out_path, \"JPEG\", quality=85)\n",
    "\n",
    "        row = {\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'album': album,\n",
    "            'source_filename': source_filename,\n",
    "            'source_type': source_type\n",
    "        }\n",
    "\n",
    "        if lat in (None, 0.0) or lon in (None, 0.0):\n",
    "            row['latitude'] = None\n",
    "            row['longitude'] = None\n",
    "            records_missing.append(row)\n",
    "        else:\n",
    "            key = (round(lat, 6), round(lon, 6))\n",
    "            count = coords_seen.get(key, 0)\n",
    "            if count > 0:\n",
    "                row['latitude'], row['longitude'] = spiral_coords(lat, lon, count)\n",
    "            coords_seen[key] = count + 1\n",
    "            records_ok.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        year, month, day = \"2099\", \"01\", \"01\"\n",
    "        base_name = f\"IMG_{year}{month}{day}_{abs(hash(source_filename)) % 10**6}.jpg\"\n",
    "        out_path = os.path.join(OUT_FOLDER, base_name)\n",
    "        records_missing.append({\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': None,\n",
    "            'longitude': None,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'album': album,\n",
    "            'source_filename': source_filename,\n",
    "            'source_type': None\n",
    "        })\n",
    "\n",
    "# === Save CSVs ===\n",
    "pd.DataFrame(records_ok).to_csv(CSV_MAIN, index=False)\n",
    "pd.DataFrame(records_missing).to_csv(CSV_MISSING, index=False)\n",
    "\n",
    "# === Summary ===\n",
    "print(f\"\\n\\U0001f4ca –°–≤–æ–¥–∫–∞:\")\n",
    "print(f\"\\U0001f9ee –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(records_ok) + len(records_missing)}\")\n",
    "print(f\"‚úÖ –° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏:   {len(records_ok)}\")\n",
    "print(f\"‚ùå –ë–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:    {len(records_missing)}\")\n",
    "print(f\"üìÑ CSV-—Ñ–∞–π–ª—ã:        {CSV_MAIN}, {CSV_MISSING}\")\n",
    "print(f\"üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:      {OUT_FOLDER}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20d7f2-fbc8-4c6d-8c18-89176c494da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e0a5d-8a9f-4a6f-a614-5cf5d9c52939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab0fb6d-912a-411b-a421-91b07a114928",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:   1%|‚ñè                | 7/653 [00:02<03:41,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0842092, lon: 14.4240219, file: IMG_1894.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1894.HEIC ‚Üí IMG_20220501_332311.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  19%|‚ñà‚ñà‚ñâ            | 127/653 [00:36<01:51,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.082902600000004, lon: 14.422433299999998, file: IMG_1899.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1899.HEIC ‚Üí IMG_20220501_71799.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 275/653 [01:21<01:32,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0877207, lon: 14.4277908, file: IMG_1811.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1811.HEIC ‚Üí IMG_20220501_135512.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 371/653 [01:49<01:07,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0864771, lon: 14.411436600000002, file: IMG_2005.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_2005.HEIC ‚Üí IMG_20220501_551842.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 391/653 [01:55<01:05,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.075538099999996, lon: 14.437800500000002, file: IMG_1890.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1890.HEIC ‚Üí IMG_20220501_429680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 426/653 [02:05<01:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0861017, lon: 14.416173599999997, file: IMG_1901.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1901.HEIC ‚Üí IMG_20220501_435404.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 653/653 [03:14<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –°–≤–æ–¥–∫–∞:\n",
      "üßÆ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 653\n",
      "‚úÖ –° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏:   653\n",
      "‚ùå –ë–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:    0\n",
      "üìÑ CSV-—Ñ–∞–π–ª—ã:        /Users/mloktionov/PycharmProjects/PhotoMaps/csv/photos.csv, /Users/mloktionov/PycharmProjects/PhotoMaps/csv/missing_coords.csv\n",
      "üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:      /Users/mloktionov/PycharmProjects/PhotoMaps/photos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from PIL import Image, ExifTags\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "ROOT = os.path.abspath(\".\")\n",
    "SRC_FOLDER = os.path.join(ROOT, \"images/PhotoMap 2022-2025\")\n",
    "OUT_FOLDER = os.path.join(ROOT, \"photos\")\n",
    "CSV_FOLDER = os.path.join(ROOT, \"csv\")\n",
    "CSV_MAIN = os.path.join(CSV_FOLDER, \"photos.csv\")\n",
    "CSV_MISSING = os.path.join(CSV_FOLDER, \"missing_coords.csv\")\n",
    "\n",
    "os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "# === Helpers ===\n",
    "def convert_to_degrees(v):\n",
    "    d, m, s = v\n",
    "    return float(d) + float(m) / 60 + float(s) / 3600\n",
    "\n",
    "def extract_gps_from_exif(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        exif_data = image._getexif()\n",
    "        if not exif_data:\n",
    "            return None, None\n",
    "\n",
    "        gps_info = {}\n",
    "        date_str = None\n",
    "        for tag, value in exif_data.items():\n",
    "            decoded = ExifTags.TAGS.get(tag)\n",
    "            if decoded == \"GPSInfo\":\n",
    "                for t in value:\n",
    "                    sub_decoded = ExifTags.GPSTAGS.get(t)\n",
    "                    gps_info[sub_decoded] = value[t]\n",
    "            elif decoded == \"DateTimeOriginal\":\n",
    "                date_str = value\n",
    "\n",
    "        if not gps_info:\n",
    "            return None, date_str\n",
    "\n",
    "        lat = convert_to_degrees(gps_info.get(\"GPSLatitude\"))\n",
    "        if gps_info.get(\"GPSLatitudeRef\") == \"S\":\n",
    "            lat = -lat\n",
    "        lon = convert_to_degrees(gps_info.get(\"GPSLongitude\"))\n",
    "        if gps_info.get(\"GPSLongitudeRef\") == \"W\":\n",
    "            lon = -lon\n",
    "\n",
    "        return (lat, lon), date_str\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def extract_gps_from_json(json_path):\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            geo = data.get(\"geoData\")\n",
    "            photo_taken_time = data.get(\"photoTakenTime\", {}).get(\"timestamp\")\n",
    "            if geo:\n",
    "                lat = geo.get(\"latitude\")\n",
    "                lon = geo.get(\"longitude\")\n",
    "                return (lat, lon), photo_taken_time\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def find_json_path_for_image(image_path):\n",
    "    base = os.path.basename(image_path)\n",
    "    folder = os.path.dirname(image_path)\n",
    "\n",
    "    suffixes = [\n",
    "        \".supplemental-metadata.json\",\n",
    "        \".supplemental-meta.json\",\n",
    "        \".supplemental-metada.json\",\n",
    "        \".supplemental-metadat.json\",\n",
    "        \".supplemental-me.json\"\n",
    "    ]\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        candidate = image_path + suffix\n",
    "        if os.path.exists(candidate):\n",
    "            return candidate\n",
    "\n",
    "    match = re.match(r'^(.*)\\((\\d+)\\)\\.(jpg|jpeg|heic)$', base, re.IGNORECASE)\n",
    "    if match:\n",
    "        base_clean = match.group(1).strip()\n",
    "        suffix_num = match.group(2)\n",
    "        ext = match.group(3)\n",
    "        for sfx in suffixes:\n",
    "            sfx_with_index = sfx.replace(\".json\", f\"({suffix_num}).json\")\n",
    "            alt_json = os.path.join(folder, f\"{base_clean}.{ext}{sfx_with_index}\")\n",
    "            if os.path.exists(alt_json):\n",
    "                return alt_json\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_date_components(date_str):\n",
    "    try:\n",
    "        if date_str and len(str(date_str)) == 10 and str(date_str).isdigit():\n",
    "            dt = datetime.fromtimestamp(int(date_str))\n",
    "        else:\n",
    "            dt = datetime.strptime(date_str, \"%Y:%m:%d %H:%M:%S\")\n",
    "        return str(dt.year), f\"{dt.month:02d}\", f\"{dt.day:02d}\"\n",
    "    except:\n",
    "        return \"2099\", \"01\", \"01\"\n",
    "\n",
    "def spiral_coords(lat, lon, index, step=0.0002):\n",
    "    angle = index * (math.pi / 3)\n",
    "    radius = step * (1 + index // 6)\n",
    "    return lat + radius * math.cos(angle), lon + radius * math.sin(angle)\n",
    "\n",
    "# === Find all images ===\n",
    "image_files = []\n",
    "for dirpath, _, filenames in os.walk(SRC_FOLDER):\n",
    "    for f in filenames:\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.heic')) and \"-edited\" not in f.lower():\n",
    "            image_files.append(os.path.join(dirpath, f))\n",
    "\n",
    "# === Processing ===\n",
    "Image.init()\n",
    "coords_seen = {}\n",
    "records_ok = []\n",
    "records_missing = []\n",
    "\n",
    "for in_path in tqdm(image_files, desc=\"\\U0001f4e6 –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\", ncols=80):\n",
    "    source_filename = os.path.basename(in_path)\n",
    "    ext = os.path.splitext(source_filename)[1].lower()\n",
    "    album = os.path.basename(os.path.dirname(in_path))\n",
    "    source_type = None\n",
    "\n",
    "    try:\n",
    "        lat, lon, date_str = None, None, None\n",
    "\n",
    "        if ext in [\".jpg\", \".jpeg\"]:\n",
    "            gps, date_str = extract_gps_from_exif(in_path)\n",
    "            if gps:\n",
    "                lat, lon = gps\n",
    "                source_type = \"exif\"\n",
    "\n",
    "        if lat is None or lon is None:\n",
    "            json_path = find_json_path_for_image(in_path)\n",
    "            if json_path:\n",
    "                gps_json, json_date = extract_gps_from_json(json_path)\n",
    "                if gps_json is not None:\n",
    "                    try:\n",
    "                        lat = float(gps_json[0])\n",
    "                        lon = float(gps_json[1])\n",
    "                        source_type = (source_type or \"\") + \"+json\"\n",
    "                        if ext == \".heic\":\n",
    "                            print(f\"[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: {lat}, lon: {lon}, file: {source_filename}\")\n",
    "                    except:\n",
    "                        lat, lon = None, None\n",
    "                if not date_str and json_date:\n",
    "                    date_str = json_date\n",
    "\n",
    "        year, month, day = parse_date_components(date_str)\n",
    "        base_name = f\"IMG_{year}{month}{day}_{abs(hash(source_filename)) % 10**6}.jpg\"\n",
    "        out_path = os.path.join(OUT_FOLDER, base_name)\n",
    "\n",
    "        if ext == \".heic\":\n",
    "            print(f\"[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {source_filename} ‚Üí {base_name}\")\n",
    "            result = subprocess.run([\n",
    "                \"sips\", \"-s\", \"format\", \"jpeg\", in_path, \"--out\", out_path\n",
    "            ], capture_output=True, text=True)\n",
    "            if result.returncode != 0:\n",
    "                print(f\"[HEIC] ‚ùå –û—à–∏–±–∫–∞ sips: {result.stderr.strip()}\")\n",
    "                image = Image.new(\"RGB\", (800, 600), (128, 128, 128))\n",
    "                image.save(out_path, \"JPEG\", quality=85)\n",
    "                source_type = (source_type or \"\") + \"+heic-error\"\n",
    "            else:\n",
    "                image = Image.open(out_path)\n",
    "        else:\n",
    "            image = Image.open(in_path)\n",
    "            width, height = image.size\n",
    "            new_size = (int(width * 0.8), int(height * 0.8))\n",
    "            image = image.resize(new_size, Image.LANCZOS)\n",
    "            image.convert(\"RGB\").save(out_path, \"JPEG\", quality=85)\n",
    "\n",
    "        row = {\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'album': album,\n",
    "            'source_filename': source_filename,\n",
    "            'source_type': source_type\n",
    "        }\n",
    "\n",
    "        if lat in (None, 0.0) or lon in (None, 0.0):\n",
    "            row['latitude'] = None\n",
    "            row['longitude'] = None\n",
    "            records_missing.append(row)\n",
    "        else:\n",
    "            key = (round(lat, 6), round(lon, 6))\n",
    "            count = coords_seen.get(key, 0)\n",
    "            if count > 0:\n",
    "                row['latitude'], row['longitude'] = spiral_coords(lat, lon, count)\n",
    "            coords_seen[key] = count + 1\n",
    "            records_ok.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        year, month, day = \"2099\", \"01\", \"01\"\n",
    "        base_name = f\"IMG_{year}{month}{day}_{abs(hash(source_filename)) % 10**6}.jpg\"\n",
    "        records_missing.append({\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': None,\n",
    "            'longitude': None,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'album': album,\n",
    "            'source_filename': source_filename,\n",
    "            'source_type': None\n",
    "        })\n",
    "\n",
    "# === Save CSVs ===\n",
    "pd.DataFrame(records_ok).to_csv(CSV_MAIN, index=False)\n",
    "pd.DataFrame(records_missing).to_csv(CSV_MISSING, index=False)\n",
    "\n",
    "# === Summary ===\n",
    "print(f\"\\n\\U0001f4ca –°–≤–æ–¥–∫–∞:\")\n",
    "print(f\"\\U0001f9ee –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(records_ok) + len(records_missing)}\")\n",
    "print(f\"‚úÖ –° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏:   {len(records_ok)}\")\n",
    "print(f\"‚ùå –ë–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:    {len(records_missing)}\")\n",
    "print(f\"üìÑ CSV-—Ñ–∞–π–ª—ã:        {CSV_MAIN}, {CSV_MISSING}\")\n",
    "print(f\"üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:      {OUT_FOLDER}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca66656-7508-4b73-a294-18a6d3ae4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- MAIN script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c580532-e4ba-44f9-84d3-77270965d3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 1427/2431 [06:35<05:51,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0842092, lon: 14.4240219, file: IMG_1894.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1894.HEIC ‚Üí IMG_20220501_332311.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1546/2431 [07:11<03:42,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.082902600000004, lon: 14.422433299999998, file: IMG_1899.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1899.HEIC ‚Üí IMG_20220501_71799.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1694/2431 [07:56<03:47,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0877207, lon: 14.4277908, file: IMG_1811.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1811.HEIC ‚Üí IMG_20220501_135512.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1790/2431 [08:25<02:58,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0864771, lon: 14.411436600000002, file: IMG_2005.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_2005.HEIC ‚Üí IMG_20220501_551842.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1810/2431 [08:31<03:08,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.075538099999996, lon: 14.437800500000002, file: IMG_1890.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1890.HEIC ‚Üí IMG_20220501_429680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1846/2431 [08:41<02:56,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: 50.0861017, lon: 14.416173599999997, file: IMG_1901.HEIC\n",
      "[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: IMG_1901.HEIC ‚Üí IMG_20220501_435404.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2431/2431 [10:46<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –°–≤–æ–¥–∫–∞:\n",
      "üßÆ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2431\n",
      "‚úÖ –° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏:   2424\n",
      "‚ùå –ë–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:    7\n",
      "üìÑ CSV-—Ñ–∞–π–ª—ã:        /Users/mloktionov/PycharmProjects/PhotoMaps/csv/photos.csv, /Users/mloktionov/PycharmProjects/PhotoMaps/csv/missing_coords.csv\n",
      "üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:      /Users/mloktionov/PycharmProjects/PhotoMaps/photos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from PIL import Image, ExifTags\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "ROOT = os.path.abspath(\".\")\n",
    "SRC_FOLDER = os.path.join(ROOT, \"images\")\n",
    "OUT_FOLDER = os.path.join(ROOT, \"photos\")\n",
    "CSV_FOLDER = os.path.join(ROOT, \"csv\")\n",
    "CSV_MAIN = os.path.join(CSV_FOLDER, \"photos.csv\")\n",
    "CSV_MISSING = os.path.join(CSV_FOLDER, \"missing_coords.csv\")\n",
    "\n",
    "os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "# === Helpers ===\n",
    "def convert_to_degrees(v):\n",
    "    d, m, s = v\n",
    "    return float(d) + float(m) / 60 + float(s) / 3600\n",
    "\n",
    "def extract_gps_from_exif(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        exif_data = image._getexif()\n",
    "        if not exif_data:\n",
    "            return None, None\n",
    "\n",
    "        gps_info = {}\n",
    "        date_str = None\n",
    "        for tag, value in exif_data.items():\n",
    "            decoded = ExifTags.TAGS.get(tag)\n",
    "            if decoded == \"GPSInfo\":\n",
    "                for t in value:\n",
    "                    sub_decoded = ExifTags.GPSTAGS.get(t)\n",
    "                    gps_info[sub_decoded] = value[t]\n",
    "            elif decoded == \"DateTimeOriginal\":\n",
    "                date_str = value\n",
    "\n",
    "        if not gps_info:\n",
    "            return None, date_str\n",
    "\n",
    "        lat = convert_to_degrees(gps_info.get(\"GPSLatitude\"))\n",
    "        if gps_info.get(\"GPSLatitudeRef\") == \"S\":\n",
    "            lat = -lat\n",
    "        lon = convert_to_degrees(gps_info.get(\"GPSLongitude\"))\n",
    "        if gps_info.get(\"GPSLongitudeRef\") == \"W\":\n",
    "            lon = -lon\n",
    "\n",
    "        return (lat, lon), date_str\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def extract_gps_from_json(json_path):\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            geo = data.get(\"geoData\")\n",
    "            photo_taken_time = data.get(\"photoTakenTime\", {}).get(\"timestamp\")\n",
    "            if geo:\n",
    "                lat = geo.get(\"latitude\")\n",
    "                lon = geo.get(\"longitude\")\n",
    "                return (lat, lon), photo_taken_time\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def find_json_path_for_image(image_path):\n",
    "    base = os.path.basename(image_path)\n",
    "    folder = os.path.dirname(image_path)\n",
    "\n",
    "    suffixes = [\n",
    "        \".supplemental-metadata.json\",\n",
    "        \".supplemental-meta.json\",\n",
    "        \".supplemental-metada.json\",\n",
    "        \".supplemental-metadat.json\",\n",
    "        \".supplemental-me.json\"\n",
    "    ]\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        candidate = image_path + suffix\n",
    "        if os.path.exists(candidate):\n",
    "            return candidate\n",
    "\n",
    "    match = re.match(r'^(.*)\\((\\d+)\\)\\.(jpg|jpeg|heic)$', base, re.IGNORECASE)\n",
    "    if match:\n",
    "        base_clean = match.group(1).strip()\n",
    "        suffix_num = match.group(2)\n",
    "        ext = match.group(3)\n",
    "        for sfx in suffixes:\n",
    "            sfx_with_index = sfx.replace(\".json\", f\"({suffix_num}).json\")\n",
    "            alt_json = os.path.join(folder, f\"{base_clean}.{ext}{sfx_with_index}\")\n",
    "            if os.path.exists(alt_json):\n",
    "                return alt_json\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_date_components(date_str):\n",
    "    try:\n",
    "        if date_str and len(str(date_str)) == 10 and str(date_str).isdigit():\n",
    "            dt = datetime.fromtimestamp(int(date_str))\n",
    "        else:\n",
    "            dt = datetime.strptime(date_str, \"%Y:%m:%d %H:%M:%S\")\n",
    "        return str(dt.year), f\"{dt.month:02d}\", f\"{dt.day:02d}\"\n",
    "    except:\n",
    "        return \"2099\", \"01\", \"01\"\n",
    "\n",
    "def spiral_coords(lat, lon, index, step=0.0002):\n",
    "    angle = index * (math.pi / 3)\n",
    "    radius = step * (1 + index // 6)\n",
    "    return lat + radius * math.cos(angle), lon + radius * math.sin(angle)\n",
    "\n",
    "# === Find all images ===\n",
    "image_files = []\n",
    "for dirpath, _, filenames in os.walk(SRC_FOLDER):\n",
    "    for f in filenames:\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.heic')) and \"-edited\" not in f.lower():\n",
    "            image_files.append(os.path.join(dirpath, f))\n",
    "\n",
    "# === Processing ===\n",
    "Image.init()\n",
    "coords_seen = {}\n",
    "records_ok = []\n",
    "records_missing = []\n",
    "\n",
    "for in_path in tqdm(image_files, desc=\"\\U0001f4e6 –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\", ncols=80):\n",
    "    source_filename = os.path.basename(in_path)\n",
    "    ext = os.path.splitext(source_filename)[1].lower()\n",
    "    album = os.path.basename(os.path.dirname(in_path))\n",
    "    source_type = None\n",
    "    lat, lon, date_str = None, None, None\n",
    "\n",
    "    try:\n",
    "        if ext in [\".jpg\", \".jpeg\"]:\n",
    "            gps, date_str = extract_gps_from_exif(in_path)\n",
    "            if gps:\n",
    "                lat, lon = gps\n",
    "                source_type = \"exif\"\n",
    "\n",
    "        if lat is None or lon is None:\n",
    "            json_path = find_json_path_for_image(in_path)\n",
    "            if json_path:\n",
    "                gps_json, json_date = extract_gps_from_json(json_path)\n",
    "                if gps_json is not None:\n",
    "                    try:\n",
    "                        lat = float(gps_json[0])\n",
    "                        lon = float(gps_json[1])\n",
    "                        source_type = (source_type or \"\") + \"+json\"\n",
    "                        if ext == \".heic\":\n",
    "                            print(f\"[HEIC] –ù–∞–π–¥–µ–Ω JSON ‚Üí lat: {lat}, lon: {lon}, file: {source_filename}\")\n",
    "                    except:\n",
    "                        lat, lon = None, None\n",
    "                if not date_str and json_date:\n",
    "                    date_str = json_date\n",
    "\n",
    "        year, month, day = parse_date_components(date_str)\n",
    "        base_name = f\"IMG_{year}{month}{day}_{abs(hash(source_filename)) % 10**6}.jpg\"\n",
    "        out_path = os.path.join(OUT_FOLDER, base_name)\n",
    "\n",
    "        if ext == \".heic\":\n",
    "            print(f\"[HEIC] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {source_filename} ‚Üí {base_name}\")\n",
    "            temp_path = \"/tmp/temp_output.jpg\"\n",
    "            result = subprocess.run([\n",
    "                \"sips\", \"-s\", \"format\", \"jpeg\", in_path, \"--out\", temp_path\n",
    "            ], capture_output=True, text=True)\n",
    "\n",
    "            if result.returncode == 0 and os.path.exists(temp_path):\n",
    "                image = Image.open(temp_path)\n",
    "                width, height = image.size\n",
    "                new_size = (int(width * 0.8), int(height * 0.8))\n",
    "                image = image.resize(new_size, Image.LANCZOS)\n",
    "                image.convert(\"RGB\").save(out_path, \"JPEG\", quality=85)\n",
    "                os.remove(temp_path)\n",
    "            else:\n",
    "                print(f\"[HEIC] ‚ùå –û—à–∏–±–∫–∞ sips: {result.stderr.strip()}\")\n",
    "                Image.new(\"RGB\", (800, 600), (128, 128, 128)).save(out_path, \"JPEG\", quality=85)\n",
    "                source_type = (source_type or \"\") + \"+heic-error\"\n",
    "\n",
    "        else:\n",
    "            image = Image.open(in_path)\n",
    "            width, height = image.size\n",
    "            new_size = (int(width * 0.8), int(height * 0.8))\n",
    "            image = image.resize(new_size, Image.LANCZOS)\n",
    "            image.convert(\"RGB\").save(out_path, \"JPEG\", quality=85)\n",
    "\n",
    "        row = {\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'album': album,\n",
    "            'source_filename': source_filename,\n",
    "            'source_type': source_type\n",
    "        }\n",
    "\n",
    "        if lat in (None, 0.0) or lon in (None, 0.0):\n",
    "            row['latitude'] = None\n",
    "            row['longitude'] = None\n",
    "            records_missing.append(row)\n",
    "        else:\n",
    "            key = (round(lat, 6), round(lon, 6))\n",
    "            count = coords_seen.get(key, 0)\n",
    "            if count > 0:\n",
    "                row['latitude'], row['longitude'] = spiral_coords(lat, lon, count)\n",
    "            coords_seen[key] = count + 1\n",
    "            records_ok.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {source_filename}: {e}\")\n",
    "        year, month, day = \"2099\", \"01\", \"01\"\n",
    "        base_name = f\"IMG_{year}{month}{day}_{abs(hash(source_filename)) % 10**6}.jpg\"\n",
    "        records_missing.append({\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': None,\n",
    "            'longitude': None,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'album': album,\n",
    "            'source_filename': source_filename,\n",
    "            'source_type': None\n",
    "        })\n",
    "\n",
    "# === Save CSVs ===\n",
    "pd.DataFrame(records_ok).to_csv(CSV_MAIN, index=False)\n",
    "pd.DataFrame(records_missing).to_csv(CSV_MISSING, index=False)\n",
    "\n",
    "# === Summary ===\n",
    "print(f\"\\n\\U0001f4ca –°–≤–æ–¥–∫–∞:\")\n",
    "print(f\"\\U0001f9ee –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(records_ok) + len(records_missing)}\")\n",
    "print(f\"‚úÖ –° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏:   {len(records_ok)}\")\n",
    "print(f\"‚ùå –ë–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:    {len(records_missing)}\")\n",
    "print(f\"üìÑ CSV-—Ñ–∞–π–ª—ã:        {CSV_MAIN}, {CSV_MISSING}\")\n",
    "print(f\"üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:      {OUT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9054893-d074-4721-886a-ea36817d15ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
