{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30572a1-6e69-4a13-8160-265f794579a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ü–∞–π–ø–ª–∞–π–Ω\n",
    "========\n",
    "–ß–∞—Å—Ç—å 3.\n",
    "\n",
    "1. –°–º–æ—Ç—Ä–∏—Ç –ø—É—Ç–∏\n",
    "2. –ì–æ—Ç–æ–≤–∏—Ç DataFrame –∏–∑ photos.csv\n",
    "3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç geojson —Å –ø–æ–ª—è–º–∏ –∏–∑ DataFrame - \n",
    "4. –î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–¥ —Å—Ç—Ä–∞–Ω—ã —á–µ—Ä–µ–∑ \"https://nominatim.openstreetmap.org/reverse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae57adb0-91ee-409b-ad45-7a7200e64f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === üìÅ –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º\n",
    "CSV_PATH = \"csv/photos.csv\"\n",
    "GEOJSON_PATH = \"geojson/photos.geojson\"\n",
    "\n",
    "# === üóÇÔ∏è –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–∞–ø–∫–∞ geojson\n",
    "if not os.path.exists('geojson'):\n",
    "    os.makedirs('geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d207ac5-aa73-4659-98fd-7ec6d0828d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === üì¶ –ß–∏—Ç–∞–µ–º CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# === üéØ –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏\n",
    "df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# === üó∫Ô∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è GeoJSON\n",
    "features = []\n",
    "for _, row in df.iterrows():\n",
    "    features.append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row['longitude'], row['latitude']]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"filename\": row['filename'],\n",
    "            \"folder\": row['folder'],\n",
    "            \"year\": row['year'],\n",
    "            \"month\": row['month'],\n",
    "            \"day\": row['day'],\n",
    "            \"source_type\": row['source_type']\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd450f52-90b9-4786-8173-7a2f8cfae131",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GeoJSON —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: geojson/photos.geojson\n",
      "üìå –í—Å–µ–≥–æ —Ç–æ—á–µ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–æ: 2431\n"
     ]
    }
   ],
   "source": [
    "# === üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª\n",
    "with open(GEOJSON_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"‚úÖ GeoJSON —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {GEOJSON_PATH}\")\n",
    "print(f\"üìå –í—Å–µ–≥–æ —Ç–æ—á–µ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {len(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2a63e-071b-4fb7-8b99-664e840ff61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51288fcf-b2de-4f7e-aff6-8ee433885b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–æ—Ç –ø–æ–ª–Ω—ã–π —Å–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π –±–µ—Ä–µ—Ç —Å—Å—ã–ª–∫–∏ –∏–∑ google_drive_links.csv, \n",
    "# –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏—Ö –≤ photos.geojson –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª photos.geojson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c46a137d-111e-44ee-84b1-b9b6d6222c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –¥–ª—è: 2431 —Ñ–æ—Ç–æ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# === üìÅ –ß—Ç–µ–Ω–∏–µ CSV\n",
    "df_links = pd.read_csv('csv/google_drive_links.csv')\n",
    "df_links['normalized'] = df_links['filename'].str.lower()\n",
    "\n",
    "# === üìÅ –ß—Ç–µ–Ω–∏–µ GeoJSON\n",
    "with open('geojson/photos.geojson', 'r', encoding='utf-8') as file:\n",
    "    geojson_data = json.load(file)\n",
    "\n",
    "missing = []\n",
    "\n",
    "# === –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ\n",
    "for feature in geojson_data['features']:\n",
    "    geo_name = feature['properties']['filename'].lower()\n",
    "    match = df_links[df_links['normalized'] == geo_name]\n",
    "\n",
    "    if not match.empty:\n",
    "        row = match.iloc[0]\n",
    "        feature['properties']['image'] = f\"https://drive.google.com/thumbnail?id={row['file_id']}\"\n",
    "        feature['properties']['fullname'] = row['link']\n",
    "        if pd.notna(row['description']) and row['description'] != 'No Description':\n",
    "            feature['properties']['description'] = row['description']\n",
    "    else:\n",
    "        missing.append(geo_name)\n",
    "\n",
    "# === üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "with open('geojson/photos.geojson', 'w', encoding='utf-8') as file:\n",
    "    json.dump(geojson_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –¥–ª—è: {len(geojson_data['features']) - len(missing)} —Ñ–æ—Ç–æ\")\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –¥–ª—è {len(missing)} —Ñ–æ—Ç–æ:\")\n",
    "    for name in missing:\n",
    "        print(f\" - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d596144-76c5-47fa-b0f6-826a84f861c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ json –ø–æ–ª–µ —Å –∫–æ–¥–æ–º —Å—Ç—Ä–∞–Ω—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b1480f2-9e18-43cf-bbad-4ffbb0f55d62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ—á–µ–∫: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2431/2431 [1:32:26<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –§–∞–π–ª geojson/photos.geojson —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω —Å –∫–æ–¥–∞–º–∏ —Å—Ç—Ä–∞–Ω.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "GEOJSON_FILE = \"geojson/photos.geojson\"\n",
    "NOMINATIM_URL = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "DELAY = 2  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ª–∏–º–∏—Ç–∞ API\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'PhotoMapsApp (example@domain.com)'\n",
    "}\n",
    "\n",
    "def get_country_code(lat, lon):\n",
    "    \"\"\"\n",
    "    –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω—ã –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º —á–µ—Ä–µ–∑ Nominatim API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(NOMINATIM_URL, params={\n",
    "            'format': 'json',\n",
    "            'lat': lat,\n",
    "            'lon': lon\n",
    "        }, headers=HEADERS)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            country_code = data.get('address', {}).get('country_code', '').upper()\n",
    "            if country_code:\n",
    "                return country_code\n",
    "            else:\n",
    "                print(f\"‚ùå –û—à–∏–±–∫–∞: –°—Ç—Ä–∞–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç {lat}, {lon}\")\n",
    "                sys.exit(1)\n",
    "        else:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: —Å—Ç–∞—Ç—É—Å {response.status_code}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def enrich_geojson():\n",
    "    \"\"\"\n",
    "    –û–±–æ–≥–∞—â–µ–Ω–∏–µ GeoJSON –¥–∞–Ω–Ω—ã–º–∏ –æ —Å—Ç—Ä–∞–Ω–µ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º\n",
    "    \"\"\"\n",
    "    with open(GEOJSON_FILE, 'r') as file:\n",
    "        geojson_data = json.load(file)\n",
    "\n",
    "    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä\n",
    "    for feature in tqdm(geojson_data[\"features\"], desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ—á–µ–∫\"):\n",
    "        lat, lon = feature[\"geometry\"][\"coordinates\"][1], feature[\"geometry\"][\"coordinates\"][0]\n",
    "        country_code = get_country_code(lat, lon)\n",
    "        feature[\"properties\"][\"country_code\"] = country_code\n",
    "        time.sleep(DELAY)  # –ü–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ —Å–ª–æ–≤–∏—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–∫—É API\n",
    "\n",
    "    with open(GEOJSON_FILE, 'w') as file:\n",
    "        json.dump(geojson_data, file, indent=4)\n",
    "        print(f\"\\n‚úÖ –§–∞–π–ª {GEOJSON_FILE} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω —Å –∫–æ–¥–∞–º–∏ —Å—Ç—Ä–∞–Ω.\")\n",
    "\n",
    "\n",
    "# === –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ ===\n",
    "enrich_geojson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039ac4b-5def-4018-8130-13ecc883bf62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
