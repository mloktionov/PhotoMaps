{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4c3cd3-3dca-4cca-a622-3650e5fba878",
   "metadata": {},
   "source": [
    "Ð’Ð¾Ñ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð´Ð²ÑƒÑ… Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð², ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ‚Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑˆÑŒ Ð² Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ðµ PhotoMaps:\n",
    "\n",
    "ðŸ› ï¸ Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ 1: Ð¡Ð¶Ð°Ñ‚Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ CSV (compress_and_index.py)\n",
    "\n",
    "Ð—Ð°Ð´Ð°Ñ‡Ð°:\n",
    "ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¸Ð· images/:\n",
    "\tâ€¢\tÐ˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ Ð¸ Ð´Ð°Ñ‚Ñƒ (EXIF + JSON)\n",
    "\tâ€¢\tÐ•ÑÐ»Ð¸ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ ÐµÑÑ‚ÑŒ â€” ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÑÐ¶Ð°Ñ‚ÑƒÑŽ ÐºÐ¾Ð¿Ð¸ÑŽ Ð² photos/\n",
    "\tâ€¢\tÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ñ‹Ð²Ð°ÐµÑ‚ Ñ„Ð°Ð¹Ð» Ð¿Ð¾ ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ IMG_YYYYMMDD_hash.jpg, ÐµÑÐ»Ð¸ Ð´Ð°Ñ‚Ð° Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð° Ð² Ð¸Ð¼ÐµÐ½Ð¸\n",
    "\tâ€¢\tÐ”Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ (Ð¸Ð¼Ñ, ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹, Ð´Ð°Ñ‚Ð°) Ð² csv/photos.csv\n",
    "\tâ€¢\tÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ñ€Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÑ‚ photos.csv Ð½Ð° Ñ„Ð°Ð¹Ð»Ñ‹ Ð¿Ð¾ Ð³Ð¾Ð´Ð°Ð¼: photos_2020.csv, photos_2021.csv Ð¸ Ñ‚.Ð´.\n",
    "\tâ€¢\tÐ’ÑÐµ Ð¾Ñ‚Ð±Ñ€Ð°ÐºÐ¾Ð²ÐºÐ¸ (Ð±ÐµÐ· ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ Ð¸Ð»Ð¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº) â€” Ð² csv/errors_combined.csv\n",
    "\n",
    "Ð’Ñ…Ð¾Ð´:\n",
    "\tâ€¢\timages/*.jpg|.jpeg\n",
    "\tâ€¢\t(Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾) .json Ñ€ÑÐ´Ð¾Ð¼ Ñ Ñ„Ð¾Ñ‚Ð¾ (.supplemental-metadata.json)\n",
    "\n",
    "Ð’Ñ‹Ñ…Ð¾Ð´:\n",
    "\tâ€¢\tphotos/*.jpg â€” ÑÐ¶Ð°Ñ‚Ñ‹Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð°Ð¼Ð¸\n",
    "\tâ€¢\tcsv/photos.csv â€” Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "\tâ€¢\tcsv/photos_YYYY.csv â€” Ñ€Ð°Ð·Ð±Ð¸Ñ‚Ñ‹Ðµ Ð¿Ð¾ Ð³Ð¾Ð´Ð°Ð¼\n",
    "\tâ€¢\tcsv/errors_combined.csv â€” Ð»Ð¾Ð³ Ð¾ÑˆÐ¸Ð±Ð¾Ðº\n",
    "\n",
    "ðŸŽ¨ Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ 2: Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¼Ð¸Ð½Ð¸Ð°Ñ‚ÑŽÑ€ (generate_thumbnails.py)\n",
    "\n",
    "Ð—Ð°Ð´Ð°Ñ‡Ð°:\n",
    "Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ ÐºÑ€ÑƒÐ³Ð»Ñ‹Ðµ Ð¼Ð¸Ð½Ð¸Ð°Ñ‚ÑŽÑ€Ñ‹ 64x64 PNG Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑÐ¶Ð°Ñ‚Ð¾Ð³Ð¾ Ñ„Ð¾Ñ‚Ð¾ Ð¸Ð· photos/, Ð¾ÐºÑ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ñ€Ð°Ð¼ÐºÑƒ Ð¿Ð¾ Ð³Ð¾Ð´Ñƒ.\n",
    "\n",
    "ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸:\n",
    "\tâ€¢\tÐŸÑ€ÐµÐ²ÑŒÑŽ Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¾ ÐºÐ°Ðº ÐºÑ€ÑƒÐ³ Ñ Ñ†Ð²ÐµÑ‚Ð½Ð¾Ð¹ Ñ€Ð°Ð¼ÐºÐ¾Ð¹\n",
    "\tâ€¢\tÐ¦Ð²ÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ Ð³Ð¾Ð´Ð° (Ð¸Ð· Ð¿Ð°Ð»Ð¸Ñ‚Ñ€Ñ‹)\n",
    "\tâ€¢\tÐÐ°Ð·Ð²Ð°Ð½Ð¸Ñ .jpg/.jpeg â†’ .png\n",
    "\n",
    "Ð’Ñ…Ð¾Ð´:\n",
    "\tâ€¢\tphotos/*.jpg\n",
    "\tâ€¢\tcsv/photos.csv (Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð³Ð¾Ð´Ð°)\n",
    "\n",
    "Ð’Ñ‹Ñ…Ð¾Ð´:\n",
    "\tâ€¢\tthumbnails/*.png â€” Ð¸ÐºÐ¾Ð½ÐºÐ¸, Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÐ¼Ñ‹Ðµ Ð½Ð° ÐºÐ°Ñ€Ñ‚Ðµ\n",
    "\n",
    "ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»Ñ‘Ð½Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½\n",
    "\t1.\timages/ â€” Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ JPG-Ñ„Ð°Ð¹Ð»Ñ‹ (Ð¸ .json Ð¿Ñ€Ð¸ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸)\n",
    "\t2.\tâ–¶ï¸ Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ 1: compress_and_index.py\n",
    "\tâ€¢\tâž¡ï¸ photos/ (JPEG, ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¸Ñ)\n",
    "\tâ€¢\tâž¡ï¸ csv/ (Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ)\n",
    "\t3.\tâ–¶ï¸ Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ 2: generate_thumbnails.py\n",
    "\tâ€¢\tâž¡ï¸ thumbnails/ (Ð¸ÐºÐ¾Ð½ÐºÐ¸ PNG)\n",
    "\t4.\tðŸ—ºï¸ ÐšÐ°Ñ€Ñ‚Ð° Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÑ‚ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ñ Ð¿Ñ€ÐµÐ²ÑŒÑŽ Ð¸ Ð¿Ð¾Ð¿Ð°Ð¿Ð°Ð¼Ð¸, Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· csv/photos_*.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566076a1-38ca-4b47-ab05-80e67e82d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- script to study our images. Retrieves how many files of which types are there in source folder images/--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60947472-f465-451f-ab86-2c9f83e42385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸: images\n",
      "===================================\n",
      "  .JPG: 2185\n",
      " .JPEG: 20\n",
      " .HEIC: 6\n",
      " .JSON: 2068\n",
      "ðŸŒ€ Ð”ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² Ñ (1), (2)...: 5\n",
      "ðŸ“‹ Ð”ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² copy         : 4\n",
      "âœ‚ï¸  -edited Ñ„Ð°Ð¹Ð»Ð¾Ð²         : 146\n",
      "===================================\n",
      "ðŸ“¦ Ð’ÑÐµÐ³Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð²: 4282\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "FOLDER = \"images\"  # Ð·Ð°Ð¼ÐµÐ½Ð¸ Ð½Ð° Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸\n",
    "files = os.listdir(FOLDER)\n",
    "\n",
    "# === Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ\n",
    "ext_counts = Counter()\n",
    "suffix_counts = Counter()\n",
    "edited_count = 0\n",
    "copy_count = 0\n",
    "\n",
    "for f in files:\n",
    "    lower = f.lower()\n",
    "    if lower.endswith(('.jpg', '.jpeg', '.heic')):\n",
    "        ext = os.path.splitext(f)[1].lower()\n",
    "        ext_counts[ext] += 1\n",
    "\n",
    "        # Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹: IMG_1234(1).JPG\n",
    "        if re.search(r'\\(\\d+\\)\\.(jpe?g|heic)$', lower):\n",
    "            suffix_counts['duplicate'] += 1\n",
    "\n",
    "        # -edited.JPG\n",
    "        if '-edited' in lower:\n",
    "            edited_count += 1\n",
    "\n",
    "        # \" copy\" Ð² Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°\n",
    "        if re.search(r' copy(\\s\\d+)?\\.(jpe?g|heic)$', lower):\n",
    "            copy_count += 1\n",
    "\n",
    "    elif lower.endswith('.json'):\n",
    "        ext_counts['.json'] += 1\n",
    "\n",
    "# === Ð’Ñ‹Ð²Ð¾Ð´\n",
    "print(f\"ðŸ“ ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸: {FOLDER}\")\n",
    "print(\"===================================\")\n",
    "for ext in ['.jpg', '.jpeg', '.heic', '.json']:\n",
    "    print(f\"{ext.upper():>6}: {ext_counts[ext]}\")\n",
    "\n",
    "print(f\"ðŸŒ€ Ð”ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² Ñ (1), (2)...: {suffix_counts['duplicate']}\")\n",
    "print(f\"ðŸ“‹ Ð”ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² copy         : {copy_count}\")\n",
    "print(f\"âœ‚ï¸  -edited Ñ„Ð°Ð¹Ð»Ð¾Ð²         : {edited_count}\")\n",
    "print(\"===================================\")\n",
    "print(f\"ðŸ“¦ Ð’ÑÐµÐ³Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð²: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4f84a-e0e6-4cf6-86c8-de983df9aea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -- duplicate images eliminator -- run every time you download the new copy of google photos\n",
    "# -- file type: IMG_1234(1).JPG, IMG_1234(2).JPG and their json (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ee59d9-8744-44b4-86b1-05e00d2ebbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð½ÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ðµ JSON Ñ„Ð°Ð¹Ð»Ñ‹:\n",
      " - EFFECTS.jpg.supplemental-metadata(1).json\n",
      " - IMG_2822.JPG.supplemental-metadata(1).json\n",
      " - IMG_0128.JPG.supplemental-metadata(1).json\n",
      "ðŸ”„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°: images/EFFECTS.jpg.supplemental-metadata(1).json\n",
      "   â†’ Ð‘Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¸Ð¼Ñ: EFFECTS.jpg, Ð˜Ð½Ð´ÐµÐºÑ: 1\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ: images/EFFECTS.jpg.supplemental-metadata(1).json â†’ images/EFFECTS(1).JPG.supplemental-metadata.json\n",
      "ðŸ”„ Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ title: EFFECTS.jpg â†’ EFFECTS(1).JPG\n",
      "ðŸ”„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°: images/IMG_2822.JPG.supplemental-metadata(1).json\n",
      "   â†’ Ð‘Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¸Ð¼Ñ: IMG_2822.JPG, Ð˜Ð½Ð´ÐµÐºÑ: 1\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ: images/IMG_2822.JPG.supplemental-metadata(1).json â†’ images/IMG_2822(1).JPG.supplemental-metadata.json\n",
      "ðŸ”„ Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ title: IMG_2822.JPG â†’ IMG_2822(1).JPG\n",
      "ðŸ”„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°: images/IMG_0128.JPG.supplemental-metadata(1).json\n",
      "   â†’ Ð‘Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¸Ð¼Ñ: IMG_0128.JPG, Ð˜Ð½Ð´ÐµÐºÑ: 1\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ: images/IMG_0128.JPG.supplemental-metadata(1).json â†’ images/IMG_0128(1).JPG.supplemental-metadata.json\n",
      "ðŸ”„ Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ title: IMG_0128.JPG â†’ IMG_0128(1).JPG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# === ðŸ“ ÐŸÐ°Ð¿ÐºÐ° Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸\n",
    "folder = \"images\"\n",
    "\n",
    "# === ðŸŽ¯ Ð ÐµÐ³ÑƒÐ»ÑÑ€ÐºÐ° Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð½ÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ñ… JSON\n",
    "pattern = re.compile(r\"(.*)\\.supplemental-metadata\\((\\d+)\\)\\.json\", re.IGNORECASE)\n",
    "\n",
    "# === ðŸ”„ ÐŸÐ¾Ð¸ÑÐº Ð²ÑÐµÑ… JSON Ñ Ð½ÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ Ð¸Ð¼ÐµÐ½ÐµÐ¼\n",
    "json_files = [f for f in os.listdir(folder) if pattern.match(f)]\n",
    "\n",
    "# === ðŸ”Ž Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹\n",
    "if json_files:\n",
    "    print(f\"ðŸ” ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð½ÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ðµ JSON Ñ„Ð°Ð¹Ð»Ñ‹:\")\n",
    "    for f in json_files:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ñ!\")\n",
    "\n",
    "for fname in json_files:\n",
    "    json_path = os.path.join(folder, fname)\n",
    "    \n",
    "    # === âœ… ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð» ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ñ„Ð°Ð¹Ð» {json_path} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¿ÐµÑ€ÐµÐ´ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼!\")\n",
    "        continue\n",
    "\n",
    "    print(f\"ðŸ”„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°: {json_path}\")\n",
    "    \n",
    "    # === ðŸ” ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ð¾Ð³Ð¾ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ\n",
    "    match = pattern.match(fname)\n",
    "    base_name, index = match.groups()\n",
    "    print(f\"   â†’ Ð‘Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð¸Ð¼Ñ: {base_name}, Ð˜Ð½Ð´ÐµÐºÑ: {index}\")\n",
    "    \n",
    "    # === ðŸ“ Ð§Ð¸ÑÑ‚Ð¸Ð¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¾Ñ‚ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ð¹, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð»Ð¸ÑÑŒ\n",
    "    if base_name.lower().endswith('.jpg'):\n",
    "        base_name = base_name[:-4]\n",
    "    elif base_name.lower().endswith('.jpeg'):\n",
    "        base_name = base_name[:-5]\n",
    "\n",
    "    # === ðŸ“ Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¸Ð¼Ñ\n",
    "    correct_name = f\"{base_name}({index}).JPG.supplemental-metadata.json\"\n",
    "    correct_path = os.path.join(folder, correct_name)\n",
    "    \n",
    "    print(f\"ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ: {json_path} â†’ {correct_path}\")\n",
    "    \n",
    "    # === ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ\n",
    "    try:\n",
    "        os.rename(json_path, correct_path)\n",
    "        \n",
    "        # === âœ… ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð» Ð¿Ð¾ÑÐ²Ð¸Ð»ÑÑ Ð¿Ð¾ÑÐ»Ðµ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ñ\n",
    "        if not os.path.exists(correct_path):\n",
    "            print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ñ„Ð°Ð¹Ð» {correct_path} Ð½Ðµ Ð¿Ð¾ÑÐ²Ð¸Ð»ÑÑ Ð¿Ð¾ÑÐ»Ðµ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ñ!\")\n",
    "            continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ð¸: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # === ðŸ”„ Ð§Ð¸Ñ‚Ð°ÐµÐ¼ JSON Ð¸ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ title\n",
    "    try:\n",
    "        with open(correct_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            metadata = json.load(file)\n",
    "        \n",
    "        # === ÐÐ¾Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ title\n",
    "        old_title = metadata.get(\"title\", \"\")\n",
    "        new_title = f\"{base_name}({index}).JPG\"\n",
    "        \n",
    "        if old_title != new_title:\n",
    "            print(f\"ðŸ”„ Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ title: {old_title} â†’ {new_title}\")\n",
    "            metadata[\"title\"] = new_title\n",
    "            \n",
    "            # === ðŸ“ Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾\n",
    "            with open(correct_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(metadata, file, ensure_ascii=False, indent=4)\n",
    "        else:\n",
    "            print(f\"âœ… Title ÑƒÐ¶Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹: {old_title}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ JSON: {correct_path} â†’ {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d88ca-b061-40d8-b452-f2da4ac44dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- duplicate images eliminator -- run every time you download the new copy of google photos\n",
    "# -- file type: IMG_1234 copy.JPG, IMG_1234 copy copy.JPG and their json (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba02a70-8a09-4aee-9dec-22cc483725b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ Ð¼ÐµÑ‚ÐºÐ¾Ð¹ ' copy': 4\n",
      "\n",
      "âœ… JSON Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ: IMG_0275 copy.JPG â†’ IMG_0275.jpg.supplemental-metadata copy.json\n",
      "ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ 'title' Ð² JSON: IMG_0275.JPG â†’ IMG_0275 copy.JPG\n",
      "âœ… JSON Ð´Ð»Ñ IMG_0275 copy.JPG ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ â†’ images/IMG_0275 copy.JPG.supplemental-metadata.json\n",
      "\n",
      "âœ… JSON Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ: IMG_0302 copy.JPG â†’ IMG_0302.jpg.supplemental-metadata copy.json\n",
      "ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ 'title' Ð² JSON: IMG_0302.JPG â†’ IMG_0302 copy.JPG\n",
      "âœ… JSON Ð´Ð»Ñ IMG_0302 copy.JPG ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ â†’ images/IMG_0302 copy.JPG.supplemental-metadata.json\n",
      "\n",
      "âœ… JSON Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ: IMG_0860 copy.JPG â†’ IMG_0860.jpg.supplemental-metadata copy.json\n",
      "ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ 'title' Ð² JSON: IMG_0860.JPG â†’ IMG_0860 copy.JPG\n",
      "âœ… JSON Ð´Ð»Ñ IMG_0860 copy.JPG ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ â†’ images/IMG_0860 copy.JPG.supplemental-metadata.json\n",
      "\n",
      "âœ… JSON Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ: IMG_0795 copy.JPG â†’ IMG_0795.jpg.supplemental-metadata copy.json\n",
      "ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ 'title' Ð² JSON: IMG_0795.JPG â†’ IMG_0795 copy.JPG\n",
      "âœ… JSON Ð´Ð»Ñ IMG_0795 copy.JPG ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ â†’ images/IMG_0795 copy.JPG.supplemental-metadata.json\n",
      "\n",
      "=== ðŸ“‹ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ˜ ===\n",
      "ðŸ” ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð²-ÐºÐ¾Ð¿Ð¸Ð¹: 4\n",
      "ðŸ“Œ Ð¤Ð°Ð¹Ð»Ð¾Ð², ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰Ð¸Ñ… EXIF: 0\n",
      "âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ JSON Ñ„Ð°Ð¹Ð»Ð¾Ð²: 4\n",
      "âŒ JSON Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ Ð±Ð¸Ñ‚Ð¼Ð°Ð¿Ð¾Ð²: 0\n",
      "\n",
      "ðŸ“‚ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²-ÐºÐ¾Ð¿Ð¸Ð¹:\n",
      " - IMG_0275 copy.JPG\n",
      " - IMG_0302 copy.JPG\n",
      " - IMG_0860 copy.JPG\n",
      " - IMG_0795 copy.JPG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "# === ðŸ“ ÐŸÐ°Ð¿ÐºÐ° Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸\n",
    "folder = \"images\"\n",
    "\n",
    "# === ðŸ—‚ï¸ ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð»Ð¸ Ð¿Ð°Ð¿ÐºÐ°\n",
    "if not os.path.exists(folder):\n",
    "    print(f\"âŒ ÐŸÐ°Ð¿ÐºÐ° '{folder}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°. Ð¡Ð¾Ð·Ð´Ð°ÑŽ ÐµÑ‘...\")\n",
    "    os.makedirs(folder)\n",
    "    print(f\"âœ… ÐŸÐ°Ð¿ÐºÐ° '{folder}' ÑÐ¾Ð·Ð´Ð°Ð½Ð°. ÐŸÐ¾Ð¼ÐµÑÑ‚Ð¸ Ð² Ð½ÐµÑ‘ Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.\")\n",
    "    exit()\n",
    "\n",
    "# === ðŸ‘ï¸ ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ GPS Ð² EXIF\n",
    "def has_gps(exif):\n",
    "    gps_tag_id = [k for k, v in ExifTags.TAGS.items() if v == \"GPSInfo\"]\n",
    "    if not gps_tag_id:\n",
    "        return False\n",
    "    gps_data = exif.get(gps_tag_id[0])\n",
    "    return bool(gps_data)\n",
    "\n",
    "# === ðŸŽ¯ Ð ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ð¾Ðµ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ñ†ÐµÐ¿Ð¾Ñ‡ÐµÐº \" copy\"\n",
    "pattern = re.compile(r\"^(.+?)( copy)+(\\s\\d+)?(\\..+)$\", re.IGNORECASE)\n",
    "candidates = [f for f in os.listdir(folder) if pattern.search(f) and f.lower().endswith(('.jpg', '.jpeg', '.png', '.heic'))]\n",
    "\n",
    "# === ðŸ—‚ï¸ Ð¡Ð¿Ð¸ÑÐºÐ¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²\n",
    "not_found_json = []\n",
    "updated_json_files = []\n",
    "missing_gps_and_json = []\n",
    "files_with_gps = []\n",
    "\n",
    "print(f\"ðŸ”Ž ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ Ð¼ÐµÑ‚ÐºÐ¾Ð¹ ' copy': {len(candidates)}\")\n",
    "\n",
    "for fname in candidates:\n",
    "    base, ext = os.path.splitext(fname)\n",
    "    original_base = base.replace(' copy', '')\n",
    "    \n",
    "    # === ðŸ”„ Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð¼ÐµÐ½Ð° JSON Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¾Ð²\n",
    "    json_candidates = [\n",
    "        f\"{original_base}.jpg.supplemental-metadata copy.json\",\n",
    "        f\"{original_base}.jpeg.supplemental-metadata copy.json\",\n",
    "        f\"{original_base}.JPG.supplemental-metadata copy.json\",\n",
    "        f\"{original_base}.JPEG.supplemental-metadata copy.json\",\n",
    "    ]\n",
    "    \n",
    "    # === ðŸ”„ Ð˜Ñ‰ÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ JSON\n",
    "    existing_jsons = [j for j in json_candidates if os.path.exists(os.path.join(folder, j))]\n",
    "    \n",
    "    if existing_jsons:\n",
    "        json_path = os.path.join(folder, existing_jsons[0])\n",
    "        print(f\"\\nâœ… JSON Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ: {fname} â†’ {existing_jsons[0]}\")\n",
    "\n",
    "        # === ðŸ“ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ñ‹Ð²Ð°ÐµÐ¼ Ð² Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚\n",
    "        new_json_name = f\"{fname}.supplemental-metadata.json\"\n",
    "        new_json_path = os.path.join(folder, new_json_name)\n",
    "        os.rename(json_path, new_json_path)\n",
    "\n",
    "        # === ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ \"title\"\n",
    "        with open(new_json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            metadata = json.load(file)\n",
    "\n",
    "        original_title = metadata.get(\"title\", \"\")\n",
    "        if original_title != fname:\n",
    "            print(f\"ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ 'title' Ð² JSON: {original_title} â†’ {fname}\")\n",
    "            metadata[\"title\"] = fname\n",
    "        \n",
    "            # === ðŸ“ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾\n",
    "            with open(new_json_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(metadata, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        updated_json_files.append(fname)\n",
    "        print(f\"âœ… JSON Ð´Ð»Ñ {fname} ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ â†’ {new_json_path}\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ JSON Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ: {fname}\")\n",
    "        not_found_json.append(fname)\n",
    "        continue\n",
    "\n",
    "    # === âœ… 1. Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ EXIF â€” Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼\n",
    "    img_path = os.path.join(folder, fname)\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        exif = img._getexif() or {}\n",
    "        if has_gps(exif):\n",
    "            files_with_gps.append(fname)\n",
    "            print(f\"ðŸŒ EXIF-ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð² {fname}, JSON Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ.\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        missing_gps_and_json.append(f\"{fname} (Ð¾ÑˆÐ¸Ð±ÐºÐ° Ñ‡Ñ‚ÐµÐ½Ð¸Ñ EXIF: {e})\")\n",
    "        print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‡Ñ‚ÐµÐ½Ð¸Ñ EXIF: {fname} â†’ {e}\")\n",
    "        continue\n",
    "\n",
    "# === ðŸ“ Ð˜Ñ‚Ð¾Ð³Ð¸\n",
    "print(\"\\n=== ðŸ“‹ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ˜ ===\")\n",
    "print(f\"ðŸ” ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð²-ÐºÐ¾Ð¿Ð¸Ð¹: {len(candidates)}\")\n",
    "print(f\"ðŸ“Œ Ð¤Ð°Ð¹Ð»Ð¾Ð², ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰Ð¸Ñ… EXIF: {len(files_with_gps)}\")\n",
    "print(f\"âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ JSON Ñ„Ð°Ð¹Ð»Ð¾Ð²: {len(updated_json_files)}\")\n",
    "print(f\"âŒ JSON Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð´Ð»Ñ Ð±Ð¸Ñ‚Ð¼Ð°Ð¿Ð¾Ð²: {len(not_found_json)}\")\n",
    "\n",
    "# === ðŸ“‚ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²-ÐºÐ¾Ð¿Ð¸Ð¹\n",
    "print(\"\\nðŸ“‚ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²-ÐºÐ¾Ð¿Ð¸Ð¹:\")\n",
    "for f in candidates:\n",
    "    print(f\" - {f}\")\n",
    "\n",
    "if not_found_json:\n",
    "    print(\"\\nâ›” Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… JSON Ð´Ð»Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹:\")\n",
    "    for f in not_found_json:\n",
    "        print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9e870-10cf-4b31-b1b8-6f371e9e0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- scripts to convert HEIC files into jpgs -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd244686-9945-4f67-8330-e39a304ddf73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° .HEIC Ð² Ð¿Ð°Ð¿ÐºÐµ images\n",
      "ÐÐ°Ð¹Ð´ÐµÐ½Ð¾: 6 HEIC Ñ„Ð°Ð¹Ð»Ð¾Ð²\n",
      "âŒ Ð‘ÐµÐ· 'ftyp': 6\n",
      " - IMG_1894.HEIC\n",
      " - IMG_1899.HEIC\n",
      " - IMG_1811.HEIC\n",
      " - IMG_2005.HEIC\n",
      " - IMG_1890.HEIC\n",
      " - IMG_1901.HEIC\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ðŸ“ Ð£ÐºÐ°Ð¶Ð¸ Ð¿ÑƒÑ‚ÑŒ Ðº Ð¿Ð°Ð¿ÐºÐµ Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸\n",
    "folder = \"images\"\n",
    "\n",
    "# ðŸ” Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ .HEIC Ñ„Ð°Ð¹Ð»Ñ‹\n",
    "heic_files = [f for f in os.listdir(folder) if f.lower().endswith(\".heic\")]\n",
    "\n",
    "invalid_files = []\n",
    "\n",
    "for fname in heic_files:\n",
    "    path = os.path.join(folder, fname)\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            header = f.read(512)\n",
    "            if b\"ftyp\" not in header:\n",
    "                invalid_files.append(fname)\n",
    "    except Exception as e:\n",
    "        invalid_files.append(f\"{fname} (Ð¾ÑˆÐ¸Ð±ÐºÐ° Ñ‡Ñ‚ÐµÐ½Ð¸Ñ: {e})\")\n",
    "\n",
    "# ðŸ“‹ Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²\n",
    "print(f\"\\nðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° .HEIC Ð² Ð¿Ð°Ð¿ÐºÐµ {folder}\")\n",
    "print(f\"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾: {len(heic_files)} HEIC Ñ„Ð°Ð¹Ð»Ð¾Ð²\")\n",
    "print(f\"âŒ Ð‘ÐµÐ· 'ftyp': {len(invalid_files)}\")\n",
    "for f in invalid_files:\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537533b6-bfc4-460f-993f-483d650b920e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½ JSON: IMG_1894.HEIC.supplemental-metadata.json â†’ IMG_1894.JPG.supplemental-metadata.json\n",
      "âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½ 'title' Ð² JSON: IMG_1894.jpg\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½ JSON: IMG_1899.HEIC.supplemental-metadata.json â†’ IMG_1899.JPG.supplemental-metadata.json\n",
      "âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½ 'title' Ð² JSON: IMG_1899.jpg\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½ JSON: IMG_1811.HEIC.supplemental-metadata.json â†’ IMG_1811.JPG.supplemental-metadata.json\n",
      "âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½ 'title' Ð² JSON: IMG_1811.jpg\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½ JSON: IMG_2005.HEIC.supplemental-metadata.json â†’ IMG_2005.JPG.supplemental-metadata.json\n",
      "âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½ 'title' Ð² JSON: IMG_2005.jpg\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½ JSON: IMG_1890.HEIC.supplemental-metadata.json â†’ IMG_1890.JPG.supplemental-metadata.json\n",
      "âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½ 'title' Ð² JSON: IMG_1890.jpg\n",
      "ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½ JSON: IMG_1901.HEIC.supplemental-metadata.json â†’ IMG_1901.JPG.supplemental-metadata.json\n",
      "âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½ 'title' Ð² JSON: IMG_1901.jpg\n",
      "\n",
      "âœ… ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾: 6 HEIC â†’ JPG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# === ðŸ“ ÐŸÐ°Ð¿ÐºÐ° Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸\n",
    "folder = \"images\"\n",
    "\n",
    "# === ðŸ” ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð²ÑÐµ HEIC Ñ„Ð°Ð¹Ð»Ñ‹\n",
    "heic_files = [f for f in os.listdir(folder) if f.lower().endswith(\".heic\")]\n",
    "converted = []\n",
    "failed = []\n",
    "\n",
    "# === ðŸ”„ ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ HEIC â†’ JPG Ð¸ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ JSON\n",
    "for fname in heic_files:\n",
    "    in_path = os.path.join(folder, fname)\n",
    "    out_name = os.path.splitext(fname)[0] + \".jpg\"\n",
    "    out_path = os.path.join(folder, out_name)\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"sips\", \"-s\", \"format\", \"jpeg\", in_path, \"--out\", out_path],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            # ðŸ—‘ï¸ Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ HEIC\n",
    "            os.remove(in_path)\n",
    "            converted.append(out_name)\n",
    "\n",
    "            # === ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ JSON\n",
    "            json_name = f\"{os.path.splitext(fname)[0]}.HEIC.supplemental-metadata.json\"\n",
    "            new_json_name = f\"{os.path.splitext(fname)[0]}.JPG.supplemental-metadata.json\"\n",
    "\n",
    "            json_path = os.path.join(folder, json_name)\n",
    "            new_json_path = os.path.join(folder, new_json_name)\n",
    "\n",
    "            if os.path.exists(json_path):\n",
    "                # === ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ JSON\n",
    "                os.rename(json_path, new_json_path)\n",
    "                print(f\"ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½ JSON: {json_name} â†’ {new_json_name}\")\n",
    "\n",
    "                # === ðŸ“ Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ \"title\" Ð²Ð½ÑƒÑ‚Ñ€Ð¸ JSON\n",
    "                try:\n",
    "                    with open(new_json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        metadata = json.load(file)\n",
    "\n",
    "                    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»Ðµ \"title\"\n",
    "                    metadata[\"title\"] = out_name\n",
    "\n",
    "                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾\n",
    "                    with open(new_json_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                        json.dump(metadata, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "                    print(f\"âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½ 'title' Ð² JSON: {out_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸ JSON {new_json_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ JSON Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {json_name}\")\n",
    "        else:\n",
    "            failed.append((fname, result.stderr.strip()))\n",
    "    except Exception as e:\n",
    "        failed.append((fname, str(e)))\n",
    "\n",
    "# === ðŸ“ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚\n",
    "print(f\"\\nâœ… ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾: {len(converted)} HEIC â†’ JPG\")\n",
    "if failed:\n",
    "    print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ¸: {len(failed)}\")\n",
    "    for fname, msg in failed:\n",
    "        print(f\" - {fname}: {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b9358-c6ad-47d0-b94b-6742515604e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- images>photos converter  - MAIN script --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e8da29-5444-4d04-83b4-e89d459899d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2065/2065 [06:49<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Ð¡ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð°Ð¼Ð¸: 2065 â†’ /Users/mloktionov/PycharmProjects/PhotoMaps/csv/photos.csv\n",
      "âš ï¸ Ð‘ÐµÐ· ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ : 0 â†’ /Users/mloktionov/PycharmProjects/PhotoMaps/csv/missing_coords.csv\n",
      "ðŸ“ Ð¤Ð¾Ñ‚Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: /Users/mloktionov/PycharmProjects/PhotoMaps/photos\n",
      "ðŸ“ Ð›Ð¾Ð³ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½ Ð²: /Users/mloktionov/PycharmProjects/PhotoMaps/csv/import_log.txt\n",
      "ðŸŒ Ð”Ð¶Ð¸Ñ‚Ñ‚ÐµÑ€ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ñ‘Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚\n",
      "\n",
      "âœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² photos.csv Ð¸ missing_coords.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ExifTags\n",
    "import pillow_heif\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import math\n",
    "\n",
    "# === ðŸ“ ÐŸÐ°Ð¿ÐºÐ¸\n",
    "ROOT = os.path.abspath(\".\")\n",
    "SRC_FOLDER = os.path.join(ROOT, \"images\")\n",
    "OUT_FOLDER = os.path.join(ROOT, \"photos\")\n",
    "CSV_FOLDER = os.path.join(ROOT, \"csv\")\n",
    "LOG_FILE = os.path.join(CSV_FOLDER, \"import_log.txt\")\n",
    "os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "CSV_MAIN = os.path.join(CSV_FOLDER, \"photos.csv\")\n",
    "CSV_MISSING = os.path.join(CSV_FOLDER, \"missing_coords.csv\")\n",
    "\n",
    "# === EXIF utils\n",
    "def convert_to_degrees(v):\n",
    "    d, m, s = v\n",
    "    return float(d) + float(m) / 60 + float(s) / 3600\n",
    "\n",
    "def extract_gps(exif):\n",
    "    gps_raw = {}\n",
    "    for tag_id, val in exif.items():\n",
    "        tag = ExifTags.TAGS.get(tag_id)\n",
    "        if tag == \"GPSInfo\":\n",
    "            for key in val:\n",
    "                gps_tag = ExifTags.GPSTAGS.get(key)\n",
    "                gps_raw[gps_tag] = val[key]\n",
    "    if 'GPSLatitude' in gps_raw and 'GPSLongitude' in gps_raw:\n",
    "        try:\n",
    "            lat = convert_to_degrees(gps_raw['GPSLatitude'])\n",
    "            if gps_raw.get('GPSLatitudeRef', 'N') != 'N':\n",
    "                lat = -lat\n",
    "            lon = convert_to_degrees(gps_raw['GPSLongitude'])\n",
    "            if gps_raw.get('GPSLongitudeRef', 'E') != 'E':\n",
    "                lon = -lon\n",
    "            return lat, lon\n",
    "        except:\n",
    "            return None, None\n",
    "    return None, None\n",
    "\n",
    "def extract_date(exif):\n",
    "    date_str = exif.get(36867) or exif.get(306)\n",
    "    if date_str:\n",
    "        match = re.match(r\"(\\d{4}):(\\d{2}):(\\d{2})\", date_str)\n",
    "        if match:\n",
    "            return match.group(1), match.group(2), match.group(3)\n",
    "    return None, None, None\n",
    "\n",
    "Image.init()\n",
    "\n",
    "def spiral_coords(lat, lon, index, step=0.0002):\n",
    "    angle = index * (math.pi / 3)\n",
    "    radius = step * (1 + index // 6)\n",
    "    return lat + radius * math.cos(angle), lon + radius * math.sin(angle)\n",
    "\n",
    "image_files = [f for f in os.listdir(SRC_FOLDER)\n",
    "               if f.lower().endswith(('.jpg', '.jpeg', '.heic')) and \"-edited\" not in f.lower()]\n",
    "\n",
    "main_records = []\n",
    "missing_records = []\n",
    "log_entries = []\n",
    "\n",
    "# === ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ-Ð±Ð°Ñ€\n",
    "for fname in tqdm(image_files, desc=\"ðŸ“¦ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹\", ncols=80):\n",
    "    in_path = os.path.join(SRC_FOLDER, fname)\n",
    "    ext = os.path.splitext(fname)[1].lower()\n",
    "\n",
    "    try:\n",
    "        if ext == \".heic\":\n",
    "            heif_file = pillow_heif.read_heif(in_path)\n",
    "            image = Image.frombytes(\n",
    "                heif_file.mode, heif_file.size, heif_file.data, \"raw\")\n",
    "            exif = image.getexif()\n",
    "            log_entries.append(f\"[HEIC] Converted and loaded: {fname}\")\n",
    "        else:\n",
    "            image = Image.open(in_path)\n",
    "            exif = image._getexif() or {}\n",
    "            log_entries.append(f\"[IMG] Loaded: {fname}\")\n",
    "\n",
    "        lat, lon = extract_gps(exif)\n",
    "        year, month, day = extract_date(exif)\n",
    "        source_type = \"EXIF\"\n",
    "\n",
    "        # === ðŸ”„ ÐŸÐ¾Ð¸ÑÐº JSON Ð´Ð»Ñ Ð²ÑÐµÑ… Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð²\n",
    "        json_candidates = glob.glob(in_path + \".supplemental*.json\")\n",
    "        \n",
    "        if not json_candidates:\n",
    "            alt_path = in_path.replace(\".jpg\", \".JPG\")\n",
    "            json_candidates = glob.glob(alt_path + \".supplemental*.json\")\n",
    "        \n",
    "        if not json_candidates:\n",
    "            alt_path = in_path.replace(\".jpeg\", \".JPEG\")\n",
    "            json_candidates = glob.glob(alt_path + \".supplemental*.json\")\n",
    "        \n",
    "        if json_candidates:\n",
    "            try:\n",
    "                with open(json_candidates[0], \"r\", encoding=\"utf-8\") as jf:\n",
    "                    meta = json.load(jf)\n",
    "                if (lat is None or lon is None) and \"geoData\" in meta:\n",
    "                    lat = meta[\"geoData\"].get(\"latitude\")\n",
    "                    lon = meta[\"geoData\"].get(\"longitude\")\n",
    "                    if lat and lon:\n",
    "                        source_type = \"JSON\"\n",
    "                        log_entries.append(f\"[JSON] Used metadata for: {fname}\")\n",
    "            except Exception as e:\n",
    "                log_entries.append(f\"[ERROR] JSON read failed for {fname}: {e}\")\n",
    "                pass\n",
    "\n",
    "        if not (year and month and day):\n",
    "            year, month, day = \"2099\", \"01\", \"01\"\n",
    "\n",
    "        if not re.search(r'IMG_\\d{8}_', fname):\n",
    "            base_name = f\"IMG_{year}{month}{day}_{abs(hash(fname)) % 10**6}.jpg\"\n",
    "        else:\n",
    "            base_name = fname.replace(\".heic\", \".jpg\").replace(\".HEIC\", \".jpg\")\n",
    "\n",
    "        out_path = os.path.join(OUT_FOLDER, base_name)\n",
    "        image.convert(\"RGB\").save(out_path, \"JPEG\", quality=85)\n",
    "        log_entries.append(f\"[SAVE] {fname} â†’ {base_name}\")\n",
    "\n",
    "        row = {\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'source_path': fname,\n",
    "            'source_type': source_type\n",
    "        }\n",
    "\n",
    "        if lat and lon:\n",
    "            main_records.append(row)\n",
    "        else:\n",
    "            missing_records.append(row)\n",
    "            log_entries.append(f\"[MISSING] {fname} â†’ No coordinates\")\n",
    "\n",
    "    except Exception as e:\n",
    "        missing_records.append({\n",
    "            'filename': fname,\n",
    "            'folder': os.path.basename(OUT_FOLDER),\n",
    "            'latitude': None,\n",
    "            'longitude': None,\n",
    "            'year': None,\n",
    "            'month': None,\n",
    "            'day': None,\n",
    "            'error': str(e),\n",
    "            'source_path': fname,\n",
    "            'source_type': None\n",
    "        })\n",
    "        log_entries.append(f\"[ERROR] {fname}: {e}\")\n",
    "\n",
    "# === Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² CSV\n",
    "pd.DataFrame(main_records).to_csv(CSV_MAIN, index=False)\n",
    "pd.DataFrame(missing_records).to_csv(CSV_MISSING, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Ð¡ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð°Ð¼Ð¸: {len(main_records)} â†’ {CSV_MAIN}\")\n",
    "print(f\"âš ï¸ Ð‘ÐµÐ· ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ : {len(missing_records)} â†’ {CSV_MISSING}\")\n",
    "print(f\"ðŸ“ Ð¤Ð¾Ñ‚Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {OUT_FOLDER}\")\n",
    "print(f\"ðŸ“ Ð›Ð¾Ð³ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½ Ð²: {LOG_FILE}\")\n",
    "print(\"ðŸŒ Ð”Ð¶Ð¸Ñ‚Ñ‚ÐµÑ€ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ñ‘Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚\")\n",
    "\n",
    "print(\"\\nâœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² photos.csv Ð¸ missing_coords.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc59c3-957c-4227-8203-3a60563f89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Generating preview thumbnails in circles of a certain color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e030abbf-8ff0-4765-ac46-b903adfe7c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸŽ¨ ÐŸÑ€ÐµÐ²ÑŒÑŽ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2065/2065 [04:34<00:00,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ÐŸÑ€ÐµÐ²ÑŒÑŽ ÑÐ¾Ð·Ð´Ð°Ð½Ð¾: 2065\n",
      "âš ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾: 0\n",
      "ðŸ“ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð²: /Users/mloktionov/PycharmProjects/PhotoMaps/thumbnails\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === ðŸ“ ÐŸÑƒÑ‚Ð¸ ===\n",
    "ROOT = os.path.abspath(\".\")\n",
    "PHOTO_FOLDER = os.path.join(ROOT, \"photos\")\n",
    "THUMBNAIL_FOLDER = os.path.join(ROOT, \"thumbnails\")\n",
    "os.makedirs(THUMBNAIL_FOLDER, exist_ok=True)\n",
    "\n",
    "# === ðŸ–¼ï¸ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹\n",
    "SIZE = (64, 64)\n",
    "BORDER_WIDTH = 4\n",
    "BORDER_COLOR = \"#888888\"\n",
    "\n",
    "# === ðŸ”„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°\n",
    "jpg_files = [f for f in os.listdir(PHOTO_FOLDER) if f.lower().endswith((\".jpg\", \".jpeg\"))]\n",
    "count = 0\n",
    "skipped = 0\n",
    "\n",
    "for fname in tqdm(jpg_files, desc=\"ðŸŽ¨ ÐŸÑ€ÐµÐ²ÑŒÑŽ\", ncols=80):\n",
    "    try:\n",
    "        in_path = os.path.join(PHOTO_FOLDER, fname)\n",
    "        out_name = fname.lower().replace(\".jpg\", \".png\").replace(\".jpeg\", \".png\")\n",
    "        out_path = os.path.join(THUMBNAIL_FOLDER, out_name)\n",
    "\n",
    "        img = Image.open(in_path).convert(\"RGBA\")\n",
    "        img = img.resize(SIZE, Image.LANCZOS)\n",
    "\n",
    "        mask = Image.new(\"L\", SIZE, 0)\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "        draw.ellipse((0, 0, SIZE[0], SIZE[1]), fill=255)\n",
    "\n",
    "        result = Image.new(\"RGBA\", SIZE)\n",
    "        result.paste(img, (0, 0), mask)\n",
    "\n",
    "        draw = ImageDraw.Draw(result)\n",
    "        inset = BORDER_WIDTH // 2\n",
    "        draw.ellipse(\n",
    "            (inset, inset, SIZE[0] - inset - 1, SIZE[1] - inset - 1),\n",
    "            outline=BORDER_COLOR, width=BORDER_WIDTH\n",
    "        )\n",
    "\n",
    "        result.save(out_path, \"PNG\")\n",
    "        count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        skipped += 1\n",
    "        print(f\"âŒ {fname}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… ÐŸÑ€ÐµÐ²ÑŒÑŽ ÑÐ¾Ð·Ð´Ð°Ð½Ð¾: {count}\")\n",
    "print(f\"âš ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾: {skipped}\")\n",
    "print(f\"ðŸ“ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð²: {THUMBNAIL_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcabf53-b8cd-4e8c-a399-7049600d3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5b1a7-690d-48d0-9307-bbfd62a6d5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
