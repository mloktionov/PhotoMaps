{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4c3cd3-3dca-4cca-a622-3650e5fba878",
   "metadata": {},
   "source": [
    "Вот описание двух финальных скриптов, которые ты используешь в пайплайне PhotoMaps:\n",
    "\n",
    "🛠️ Скрипт 1: Сжатие изображений и генерация CSV (compress_and_index.py)\n",
    "\n",
    "Задача:\n",
    "Обрабатывает файлы из images/:\n",
    "\t•\tИзвлекает координаты и дату (EXIF + JSON)\n",
    "\t•\tЕсли координаты есть — сохраняет сжатую копию в photos/\n",
    "\t•\tПереименовывает файл по шаблону IMG_YYYYMMDD_hash.jpg, если дата не указана в имени\n",
    "\t•\tДобавляет информацию (имя, координаты, дата) в csv/photos.csv\n",
    "\t•\tАвтоматически разбивает photos.csv на файлы по годам: photos_2020.csv, photos_2021.csv и т.д.\n",
    "\t•\tВсе отбраковки (без координат или ошибок) — в csv/errors_combined.csv\n",
    "\n",
    "Вход:\n",
    "\t•\timages/*.jpg|.jpeg\n",
    "\t•\t(опционально) .json рядом с фото (.supplemental-metadata.json)\n",
    "\n",
    "Выход:\n",
    "\t•\tphotos/*.jpg — сжатые изображения с гарантированными координатами\n",
    "\t•\tcsv/photos.csv — полный набор метаданных\n",
    "\t•\tcsv/photos_YYYY.csv — разбитые по годам\n",
    "\t•\tcsv/errors_combined.csv — лог ошибок\n",
    "\n",
    "🎨 Скрипт 2: Генерация миниатюр (generate_thumbnails.py)\n",
    "\n",
    "Задача:\n",
    "Создает круглые миниатюры 64x64 PNG для каждого сжатого фото из photos/, окрашивает рамку по году.\n",
    "\n",
    "Особенности:\n",
    "\t•\tПревью оформлено как круг с цветной рамкой\n",
    "\t•\tЦвет зависит от года (из палитры)\n",
    "\t•\tНазвания .jpg/.jpeg → .png\n",
    "\n",
    "Вход:\n",
    "\t•\tphotos/*.jpg\n",
    "\t•\tcsv/photos.csv (для определения года)\n",
    "\n",
    "Выход:\n",
    "\t•\tthumbnails/*.png — иконки, отображаемые на карте\n",
    "\n",
    "🔄 Обновлённый пайплайн\n",
    "\t1.\timages/ — исходные JPG-файлы (и .json при наличии)\n",
    "\t2.\t▶️ Скрипт 1: compress_and_index.py\n",
    "\t•\t➡️ photos/ (JPEG, компрессия)\n",
    "\t•\t➡️ csv/ (метаданные)\n",
    "\t3.\t▶️ Скрипт 2: generate_thumbnails.py\n",
    "\t•\t➡️ thumbnails/ (иконки PNG)\n",
    "\t4.\t🗺️ Карта отображает точки с превью и попапами, данные из csv/photos_*.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7142a54-d80e-48b5-b9e1-f06db72ba5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Пайплайн\n",
    "=======\n",
    "\n",
    "0. ВСЕ фото положить в папку images/\n",
    "\n",
    "PhotoMaps.ipynb - \n",
    "1. script to study our images. Retrieves how many files of which types are there in source folder images/--\n",
    "\n",
    "OUTPUT\n",
    "📁 Анализ папки: images\n",
    "===================================\n",
    "  .JPG: 2185\n",
    " .JPEG: 20\n",
    " .HEIC: 6\n",
    " .JSON: 2068\n",
    "🌀 Дубликатов с (1), (2)...: 5\n",
    "📋 Дубликатов copy         : 4\n",
    "✂️  -edited файлов         : 146\n",
    "===================================\n",
    "📦 Всего файлов: 4282\n",
    "\n",
    "2. # -- duplicate images eliminator -- run every time you download the new copy of google photos\n",
    "# -- file type: IMG_1234(1).JPG, IMG_1234(2).JPG and their json (if any)\n",
    "\n",
    "OUTPUT\n",
    "🔍 Найдены неправильные JSON файлы:\n",
    " - EFFECTS.jpg.supplemental-metadata(1).json\n",
    " - IMG_2822.JPG.supplemental-metadata(1).json\n",
    " - IMG_0128.JPG.supplemental-metadata(1).json\n",
    "\n",
    "3. # -- duplicate images eliminator -- run every time you download the new copy of google photos\n",
    "# -- file type: IMG_1234 copy.JPG, IMG_1234 copy copy.JPG and their json (if any)\n",
    "\n",
    "=== 📋 РЕЗУЛЬТАТЫ ОБРАБОТКИ ===\n",
    "🔍 Найдено файлов-копий: 4\n",
    "📌 Файлов, содержащих EXIF: 0\n",
    "✅ Успешно обработано JSON файлов: 4\n",
    "❌ JSON не найден для битмапов: 0\n",
    "\n",
    "4. # -- scripts to check HEIC files  -- \n",
    "🔍 Проверка .HEIC в папке images\n",
    "Найдено: 6 HEIC файлов\n",
    "❌ Без 'ftyp': 6\n",
    " - IMG_1894.HEIC\n",
    " - IMG_1899.HEIC\n",
    "\n",
    "5. # -- HEIC > JPG converter\n",
    "✅ Конвертировано и удалено: 6 HEIC → JPG\n",
    "\n",
    "6. # --- images>photos converter  - MAIN script --\n",
    "✅ С координатами: 2065 → /Users/mloktionov/PycharmProjects/PhotoMaps/csv/photos.csv\n",
    "⚠️ Без координат : 0 → /Users/mloktionov/PycharmProjects/PhotoMaps/csv/missing_coords.csv\n",
    "📁 Фото сохранены в: /Users/mloktionov/PycharmProjects/PhotoMaps/photos\n",
    "📝 Лог записан в: /Users/mloktionov/PycharmProjects/PhotoMaps/csv/import_log.txt\n",
    "🌍 Джиттер применён для повторяющихся координат\n",
    "\n",
    "✅ Завершено. Результаты в photos.csv и missing_coords.csv\n",
    "\n",
    "7. # ------ Generating preview thumbnails in circles of a certain color (now OBSOLETE)\n",
    "\n",
    "(уже не нужен)\n",
    "\n",
    "✅ Превью создано: 2065\n",
    "⚠️ Пропущено: 0\n",
    "📁 Сохранено в: /Users/mloktionov/PycharmProjects/PhotoMaps/thumbnails\n",
    "\n",
    "8. # ---- Getting descriptions from Google photos via API\n",
    "\n",
    "🔍 Поиск альбомов в Google Photos...\n",
    "✅ Найдены альбомы: ['PhotoMap 2022-2025', 'PhotoMap 2019-2021', 'PhotoMap 2017-2019', 'PhotoMap 2014-2016']\n",
    "\n",
    "📂 Альбом: PhotoMap 2022-2025\n",
    "Загрузка из PhotoMap 2022-2025: 653фото [00:07, 89.61фото/s] \n",
    "\n",
    "📂 Альбом: PhotoMap 2019-2021\n",
    "Загрузка из PhotoMap 2019-2021: 784фото [00:07, 100.08фото/s]\n",
    "\n",
    "📂 Альбом: PhotoMap 2017-2019\n",
    "Загрузка из PhotoMap 2017-2019: 249фото [00:02, 95.38фото/s] \n",
    "\n",
    "📂 Альбом: PhotoMap 2014-2016\n",
    "Загрузка из PhotoMap 2014-2016: 381фото [00:05, 75.50фото/s]\n",
    "\n",
    "✅ Все данные успешно записаны в csv/photos_descriptions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566076a1-38ca-4b47-ab05-80e67e82d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- script to study our images. Retrieves how many files of which types are there in source folder images/--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60947472-f465-451f-ab86-2c9f83e42385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "FOLDER = \"images\"  # замени на абсолютный путь при необходимости\n",
    "files = os.listdir(FOLDER)\n",
    "\n",
    "# === Расширения\n",
    "ext_counts = Counter()\n",
    "suffix_counts = Counter()\n",
    "edited_count = 0\n",
    "copy_count = 0\n",
    "\n",
    "for f in files:\n",
    "    lower = f.lower()\n",
    "    if lower.endswith(('.jpg', '.jpeg', '.heic')):\n",
    "        ext = os.path.splitext(f)[1].lower()\n",
    "        ext_counts[ext] += 1\n",
    "\n",
    "        # дубликаты: IMG_1234(1).JPG\n",
    "        if re.search(r'\\(\\d+\\)\\.(jpe?g|heic)$', lower):\n",
    "            suffix_counts['duplicate'] += 1\n",
    "\n",
    "        # -edited.JPG\n",
    "        if '-edited' in lower:\n",
    "            edited_count += 1\n",
    "\n",
    "        # \" copy\" в имени файла\n",
    "        if re.search(r' copy(\\s\\d+)?\\.(jpe?g|heic)$', lower):\n",
    "            copy_count += 1\n",
    "\n",
    "    elif lower.endswith('.json'):\n",
    "        ext_counts['.json'] += 1\n",
    "\n",
    "# === Вывод\n",
    "print(f\"📁 Анализ папки: {FOLDER}\")\n",
    "print(\"===================================\")\n",
    "for ext in ['.jpg', '.jpeg', '.heic', '.json']:\n",
    "    print(f\"{ext.upper():>6}: {ext_counts[ext]}\")\n",
    "\n",
    "print(f\"🌀 Дубликатов с (1), (2)...: {suffix_counts['duplicate']}\")\n",
    "print(f\"📋 Дубликатов copy         : {copy_count}\")\n",
    "print(f\"✂️  -edited файлов         : {edited_count}\")\n",
    "print(\"===================================\")\n",
    "print(f\"📦 Всего файлов: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4f84a-e0e6-4cf6-86c8-de983df9aea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -- duplicate images eliminator -- run every time you download the new copy of google photos\n",
    "# -- file type: IMG_1234(1).JPG, IMG_1234(2).JPG and their json (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee59d9-8744-44b4-86b1-05e00d2ebbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# === 📁 Папка с изображениями\n",
    "folder = \"images\"\n",
    "\n",
    "# === 🎯 Регулярка для поиска неправильных JSON\n",
    "pattern = re.compile(r\"(.*)\\.supplemental-metadata\\((\\d+)\\)\\.json\", re.IGNORECASE)\n",
    "\n",
    "# === 🔄 Поиск всех JSON с неправильным именем\n",
    "json_files = [f for f in os.listdir(folder) if pattern.match(f)]\n",
    "\n",
    "# === 🔎 Логируем найденные файлы\n",
    "if json_files:\n",
    "    print(f\"🔍 Найдены неправильные JSON файлы:\")\n",
    "    for f in json_files:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"⚠️ Не найдено файлов для переименования!\")\n",
    "\n",
    "for fname in json_files:\n",
    "    json_path = os.path.join(folder, fname)\n",
    "    \n",
    "    # === ✅ Проверяем, что файл существует\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"❌ Ошибка: файл {json_path} не найден перед переименованием!\")\n",
    "        continue\n",
    "\n",
    "    print(f\"🔄 Обработка файла: {json_path}\")\n",
    "    \n",
    "    # === 🔍 Получаем данные из регулярного выражения\n",
    "    match = pattern.match(fname)\n",
    "    base_name, index = match.groups()\n",
    "    print(f\"   → Базовое имя: {base_name}, Индекс: {index}\")\n",
    "    \n",
    "    # === 📝 Чистим название от расширений, чтобы не дублировались\n",
    "    if base_name.lower().endswith('.jpg'):\n",
    "        base_name = base_name[:-4]\n",
    "    elif base_name.lower().endswith('.jpeg'):\n",
    "        base_name = base_name[:-5]\n",
    "\n",
    "    # === 📝 Формируем правильное имя\n",
    "    correct_name = f\"{base_name}({index}).JPG.supplemental-metadata.json\"\n",
    "    correct_path = os.path.join(folder, correct_name)\n",
    "    \n",
    "    print(f\"🔄 Переименование: {json_path} → {correct_path}\")\n",
    "    \n",
    "    # === 🔄 Переименование\n",
    "    try:\n",
    "        os.rename(json_path, correct_path)\n",
    "        \n",
    "        # === ✅ Проверяем, что файл появился после переименования\n",
    "        if not os.path.exists(correct_path):\n",
    "            print(f\"❌ Ошибка: файл {correct_path} не появился после переименования!\")\n",
    "            continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при переименовании: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # === 🔄 Читаем JSON и исправляем title\n",
    "    try:\n",
    "        with open(correct_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            metadata = json.load(file)\n",
    "        \n",
    "        # === Новое значение для title\n",
    "        old_title = metadata.get(\"title\", \"\")\n",
    "        new_title = f\"{base_name}({index}).JPG\"\n",
    "        \n",
    "        if old_title != new_title:\n",
    "            print(f\"🔄 Исправление title: {old_title} → {new_title}\")\n",
    "            metadata[\"title\"] = new_title\n",
    "            \n",
    "            # === 📝 Записываем обратно\n",
    "            with open(correct_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(metadata, file, ensure_ascii=False, indent=4)\n",
    "        else:\n",
    "            print(f\"✅ Title уже корректный: {old_title}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при обработке JSON: {correct_path} → {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d88ca-b061-40d8-b452-f2da4ac44dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- duplicate images eliminator -- run every time you download the new copy of google photos\n",
    "# -- file type: IMG_1234 copy.JPG, IMG_1234 copy copy.JPG and their json (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba02a70-8a09-4aee-9dec-22cc483725b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "# === 📁 Папка с изображениями\n",
    "folder = \"images\"\n",
    "\n",
    "# === 🗂️ Проверяем, существует ли папка\n",
    "if not os.path.exists(folder):\n",
    "    print(f\"❌ Папка '{folder}' не найдена. Создаю её...\")\n",
    "    os.makedirs(folder)\n",
    "    print(f\"✅ Папка '{folder}' создана. Помести в неё файлы для обработки.\")\n",
    "    exit()\n",
    "\n",
    "# === 👁️ Проверка на наличие GPS в EXIF\n",
    "def has_gps(exif):\n",
    "    gps_tag_id = [k for k, v in ExifTags.TAGS.items() if v == \"GPSInfo\"]\n",
    "    if not gps_tag_id:\n",
    "        return False\n",
    "    gps_data = exif.get(gps_tag_id[0])\n",
    "    return bool(gps_data)\n",
    "\n",
    "# === 🎯 Регулярное выражение для поиска цепочек \" copy\"\n",
    "pattern = re.compile(r\"^(.+?)( copy)+(\\s\\d+)?(\\..+)$\", re.IGNORECASE)\n",
    "candidates = [f for f in os.listdir(folder) if pattern.search(f) and f.lower().endswith(('.jpg', '.jpeg', '.png', '.heic'))]\n",
    "\n",
    "# === 🗂️ Списки результатов\n",
    "not_found_json = []\n",
    "updated_json_files = []\n",
    "missing_gps_and_json = []\n",
    "files_with_gps = []\n",
    "\n",
    "print(f\"🔎 Найдено файлов с меткой ' copy': {len(candidates)}\")\n",
    "\n",
    "for fname in candidates:\n",
    "    base, ext = os.path.splitext(fname)\n",
    "    original_base = base.replace(' copy', '')\n",
    "    \n",
    "    # === 🔄 Формируем имена JSON для всех регистров\n",
    "    json_candidates = [\n",
    "        f\"{original_base}.jpg.supplemental-metadata copy.json\",\n",
    "        f\"{original_base}.jpeg.supplemental-metadata copy.json\",\n",
    "        f\"{original_base}.JPG.supplemental-metadata copy.json\",\n",
    "        f\"{original_base}.JPEG.supplemental-metadata copy.json\",\n",
    "    ]\n",
    "    \n",
    "    # === 🔄 Ищем существующие JSON\n",
    "    existing_jsons = [j for j in json_candidates if os.path.exists(os.path.join(folder, j))]\n",
    "    \n",
    "    if existing_jsons:\n",
    "        json_path = os.path.join(folder, existing_jsons[0])\n",
    "        print(f\"\\n✅ JSON найден для: {fname} → {existing_jsons[0]}\")\n",
    "\n",
    "        # === 📝 Переименовываем в правильный формат\n",
    "        new_json_name = f\"{fname}.supplemental-metadata.json\"\n",
    "        new_json_path = os.path.join(folder, new_json_name)\n",
    "        os.rename(json_path, new_json_path)\n",
    "\n",
    "        # === 🔄 Обновляем \"title\"\n",
    "        with open(new_json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            metadata = json.load(file)\n",
    "\n",
    "        original_title = metadata.get(\"title\", \"\")\n",
    "        if original_title != fname:\n",
    "            print(f\"🔄 Обновление 'title' в JSON: {original_title} → {fname}\")\n",
    "            metadata[\"title\"] = fname\n",
    "        \n",
    "            # === 📝 Сохраняем обратно\n",
    "            with open(new_json_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(metadata, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        updated_json_files.append(fname)\n",
    "        print(f\"✅ JSON для {fname} успешно обработан → {new_json_path}\")\n",
    "    else:\n",
    "        print(f\"\\n❌ JSON не найден для: {fname}\")\n",
    "        not_found_json.append(fname)\n",
    "        continue\n",
    "\n",
    "    # === ✅ 1. Если есть EXIF — пропускаем\n",
    "    img_path = os.path.join(folder, fname)\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        exif = img._getexif() or {}\n",
    "        if has_gps(exif):\n",
    "            files_with_gps.append(fname)\n",
    "            print(f\"🌍 EXIF-координаты найдены в {fname}, JSON не требуется.\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        missing_gps_and_json.append(f\"{fname} (ошибка чтения EXIF: {e})\")\n",
    "        print(f\"❌ Ошибка чтения EXIF: {fname} → {e}\")\n",
    "        continue\n",
    "\n",
    "# === 📝 Итоги\n",
    "print(\"\\n=== 📋 РЕЗУЛЬТАТЫ ОБРАБОТКИ ===\")\n",
    "print(f\"🔍 Найдено файлов-копий: {len(candidates)}\")\n",
    "print(f\"📌 Файлов, содержащих EXIF: {len(files_with_gps)}\")\n",
    "print(f\"✅ Успешно обработано JSON файлов: {len(updated_json_files)}\")\n",
    "print(f\"❌ JSON не найден для битмапов: {len(not_found_json)}\")\n",
    "\n",
    "# === 📂 Полный список всех найденных файлов-копий\n",
    "print(\"\\n📂 Полный список всех найденных файлов-копий:\")\n",
    "for f in candidates:\n",
    "    print(f\" - {f}\")\n",
    "\n",
    "if not_found_json:\n",
    "    print(\"\\n⛔ Список не найденных JSON для изображений:\")\n",
    "    for f in not_found_json:\n",
    "        print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9e870-10cf-4b31-b1b8-6f371e9e0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- scripts to convert HEIC files into jpgs -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd244686-9945-4f67-8330-e39a304ddf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 📁 Укажи путь к папке с изображениями\n",
    "folder = \"images\"\n",
    "\n",
    "# 🔍 Собираем все .HEIC файлы\n",
    "heic_files = [f for f in os.listdir(folder) if f.lower().endswith(\".heic\")]\n",
    "\n",
    "invalid_files = []\n",
    "\n",
    "for fname in heic_files:\n",
    "    path = os.path.join(folder, fname)\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            header = f.read(512)\n",
    "            if b\"ftyp\" not in header:\n",
    "                invalid_files.append(fname)\n",
    "    except Exception as e:\n",
    "        invalid_files.append(f\"{fname} (ошибка чтения: {e})\")\n",
    "\n",
    "# 📋 Выводим список подозрительных файлов\n",
    "print(f\"\\n🔍 Проверка .HEIC в папке {folder}\")\n",
    "print(f\"Найдено: {len(heic_files)} HEIC файлов\")\n",
    "print(f\"❌ Без 'ftyp': {len(invalid_files)}\")\n",
    "for f in invalid_files:\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83b9f5-9ce2-4bc3-854e-f886b6d4f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- HEIC > JPG converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537533b6-bfc4-460f-993f-483d650b920e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# === 📁 Папка с изображениями\n",
    "folder = \"images\"\n",
    "\n",
    "# === 🔍 Находим все HEIC файлы\n",
    "heic_files = [f for f in os.listdir(folder) if f.lower().endswith(\".heic\")]\n",
    "converted = []\n",
    "failed = []\n",
    "\n",
    "# === 🔄 Конвертация HEIC → JPG и переименование JSON\n",
    "for fname in heic_files:\n",
    "    in_path = os.path.join(folder, fname)\n",
    "    out_name = os.path.splitext(fname)[0] + \".jpg\"\n",
    "    out_path = os.path.join(folder, out_name)\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"sips\", \"-s\", \"format\", \"jpeg\", in_path, \"--out\", out_path],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            # 🗑️ Удаляем исходный HEIC\n",
    "            os.remove(in_path)\n",
    "            converted.append(out_name)\n",
    "\n",
    "            # === 🔄 Переименование JSON\n",
    "            json_name = f\"{os.path.splitext(fname)[0]}.HEIC.supplemental-metadata.json\"\n",
    "            new_json_name = f\"{os.path.splitext(fname)[0]}.JPG.supplemental-metadata.json\"\n",
    "\n",
    "            json_path = os.path.join(folder, json_name)\n",
    "            new_json_path = os.path.join(folder, new_json_name)\n",
    "\n",
    "            if os.path.exists(json_path):\n",
    "                # === 🔄 Переименование JSON\n",
    "                os.rename(json_path, new_json_path)\n",
    "                print(f\"🔄 Переименован JSON: {json_name} → {new_json_name}\")\n",
    "\n",
    "                # === 📝 Исправляем \"title\" внутри JSON\n",
    "                try:\n",
    "                    with open(new_json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        metadata = json.load(file)\n",
    "\n",
    "                    # Обновляем поле \"title\"\n",
    "                    metadata[\"title\"] = out_name\n",
    "\n",
    "                    # Сохраняем обратно\n",
    "                    with open(new_json_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                        json.dump(metadata, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "                    print(f\"✅ Обновлен 'title' в JSON: {out_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Ошибка при обновлении JSON {new_json_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"⚠️ JSON не найден: {json_name}\")\n",
    "        else:\n",
    "            failed.append((fname, result.stderr.strip()))\n",
    "    except Exception as e:\n",
    "        failed.append((fname, str(e)))\n",
    "\n",
    "# === 📝 Результат\n",
    "print(f\"\\n✅ Конвертировано и удалено: {len(converted)} HEIC → JPG\")\n",
    "if failed:\n",
    "    print(f\"❌ Ошибки: {len(failed)}\")\n",
    "    for fname, msg in failed:\n",
    "        print(f\" - {fname}: {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b9358-c6ad-47d0-b94b-6742515604e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- images>photos converter  - MAIN script --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d48c0-6e05-44b1-9537-681024cc4289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ExifTags\n",
    "import pillow_heif\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import math\n",
    "\n",
    "# === 📁 Папки\n",
    "ROOT = os.path.abspath(\".\")\n",
    "SRC_FOLDER = os.path.join(ROOT, \"images\")\n",
    "OUT_FOLDER = os.path.join(ROOT, \"photos\")\n",
    "MISSING_FOLDER = os.path.join(ROOT, \"missing_coords\")\n",
    "CSV_FOLDER = os.path.join(ROOT, \"csv\")\n",
    "LOG_FILE = os.path.join(CSV_FOLDER, \"import_log.txt\")\n",
    "\n",
    "os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(MISSING_FOLDER, exist_ok=True)\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "CSV_MAIN = os.path.join(CSV_FOLDER, \"photos.csv\")\n",
    "CSV_MISSING = os.path.join(CSV_FOLDER, \"missing_coords.csv\")\n",
    "\n",
    "# === EXIF utils\n",
    "def convert_to_degrees(v):\n",
    "    d, m, s = v\n",
    "    return float(d) + float(m) / 60 + float(s) / 3600\n",
    "\n",
    "def extract_gps(exif):\n",
    "    gps_raw = {}\n",
    "    for tag_id, val in exif.items():\n",
    "        tag = ExifTags.TAGS.get(tag_id)\n",
    "        if tag == \"GPSInfo\":\n",
    "            for key in val:\n",
    "                gps_tag = ExifTags.GPSTAGS.get(key)\n",
    "                gps_raw[gps_tag] = val[key]\n",
    "    if 'GPSLatitude' in gps_raw and 'GPSLongitude' in gps_raw:\n",
    "        try:\n",
    "            lat = convert_to_degrees(gps_raw['GPSLatitude'])\n",
    "            if gps_raw.get('GPSLatitudeRef', 'N') != 'N':\n",
    "                lat = -lat\n",
    "            lon = convert_to_degrees(gps_raw['GPSLongitude'])\n",
    "            if gps_raw.get('GPSLongitudeRef', 'E') != 'E':\n",
    "                lon = -lon\n",
    "            return lat, lon\n",
    "        except:\n",
    "            return None, None\n",
    "    return None, None\n",
    "\n",
    "def extract_date(exif):\n",
    "    date_str = exif.get(36867) or exif.get(306)\n",
    "    if date_str:\n",
    "        match = re.match(r\"(\\d{4}):(\\d{2}):(\\d{2})\", date_str)\n",
    "        if match:\n",
    "            return match.group(1), match.group(2), match.group(3)\n",
    "    return None, None, None\n",
    "\n",
    "Image.init()\n",
    "\n",
    "def spiral_coords(lat, lon, index, step=0.0002):\n",
    "    angle = index * (math.pi / 3)\n",
    "    radius = step * (1 + index // 6)\n",
    "    return lat + radius * math.cos(angle), lon + radius * math.sin(angle)\n",
    "\n",
    "image_files = [f for f in os.listdir(SRC_FOLDER)\n",
    "               if f.lower().endswith(('.jpg', '.jpeg', '.heic')) and \"-edited\" not in f.lower()]\n",
    "\n",
    "main_records = []\n",
    "missing_records = []\n",
    "log_entries = []\n",
    "\n",
    "for fname in tqdm(image_files, desc=\"📦 Обработка изображений\", ncols=80):\n",
    "    in_path = os.path.join(SRC_FOLDER, fname)\n",
    "    ext = os.path.splitext(fname)[1].lower()\n",
    "\n",
    "    try:\n",
    "        if ext == \".heic\":\n",
    "            heif_file = pillow_heif.read_heif(in_path)\n",
    "            image = Image.frombytes(heif_file.mode, heif_file.size, heif_file.data, \"raw\")\n",
    "            exif = image.getexif()\n",
    "            log_entries.append(f\"[HEIC] Converted and loaded: {fname}\")\n",
    "        else:\n",
    "            image = Image.open(in_path)\n",
    "            exif = image._getexif() or {}\n",
    "            log_entries.append(f\"[IMG] Loaded: {fname}\")\n",
    "\n",
    "        lat, lon = extract_gps(exif)\n",
    "        year, month, day = extract_date(exif)\n",
    "        source_type = \"EXIF\"\n",
    "\n",
    "        json_candidates = glob.glob(in_path + \".supplemental*.json\")\n",
    "        if not json_candidates:\n",
    "            alt_path = in_path.replace(\".jpg\", \".JPG\")\n",
    "            json_candidates = glob.glob(alt_path + \".supplemental*.json\")\n",
    "        if not json_candidates:\n",
    "            alt_path = in_path.replace(\".jpeg\", \".JPEG\")\n",
    "            json_candidates = glob.glob(alt_path + \".supplemental*.json\")\n",
    "\n",
    "        if json_candidates:\n",
    "            try:\n",
    "                with open(json_candidates[0], \"r\", encoding=\"utf-8\") as jf:\n",
    "                    meta = json.load(jf)\n",
    "                if (lat is None or lon is None) and \"geoData\" in meta:\n",
    "                    lat = meta[\"geoData\"].get(\"latitude\")\n",
    "                    lon = meta[\"geoData\"].get(\"longitude\")\n",
    "                    if lat and lon:\n",
    "                        source_type = \"JSON\"\n",
    "                        log_entries.append(f\"[JSON] Used metadata for: {fname}\")\n",
    "            except Exception as e:\n",
    "                log_entries.append(f\"[ERROR] JSON read failed for {fname}: {e}\")\n",
    "                pass\n",
    "\n",
    "        if not (year and month and day):\n",
    "            year, month, day = \"2099\", \"01\", \"01\"\n",
    "\n",
    "        if not re.search(r'IMG_\\d{8}_', fname):\n",
    "            base_name = f\"IMG_{year}{month}{day}_{abs(hash(fname)) % 10**6}.jpg\"\n",
    "        else:\n",
    "            base_name = fname.replace(\".heic\", \".jpg\").replace(\".HEIC\", \".jpg\")\n",
    "\n",
    "        if lat and lon:\n",
    "            out_path = os.path.join(OUT_FOLDER, base_name)\n",
    "        else:\n",
    "            out_path = os.path.join(MISSING_FOLDER, base_name)\n",
    "\n",
    "        image.convert(\"RGB\").save(out_path, \"JPEG\", quality=85)\n",
    "        log_entries.append(f\"[SAVE] {fname} → {out_path}\")\n",
    "\n",
    "        row = {\n",
    "            'filename': base_name,\n",
    "            'folder': os.path.basename(OUT_FOLDER if lat and lon else MISSING_FOLDER),\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'source_path': fname,\n",
    "            'source_type': source_type\n",
    "        }\n",
    "\n",
    "        if lat and lon:\n",
    "            main_records.append(row)\n",
    "        else:\n",
    "            missing_records.append(row)\n",
    "            log_entries.append(f\"[MISSING] {fname} → No coordinates\")\n",
    "\n",
    "    except Exception as e:\n",
    "        missing_records.append({\n",
    "            'filename': fname,\n",
    "            'folder': os.path.basename(MISSING_FOLDER),\n",
    "            'latitude': None,\n",
    "            'longitude': None,\n",
    "            'year': None,\n",
    "            'month': None,\n",
    "            'day': None,\n",
    "            'error': str(e),\n",
    "            'source_path': fname,\n",
    "            'source_type': None\n",
    "        })\n",
    "        log_entries.append(f\"[ERROR] {fname}: {e}\")\n",
    "\n",
    "pd.DataFrame(main_records).to_csv(CSV_MAIN, index=False)\n",
    "pd.DataFrame(missing_records).to_csv(CSV_MISSING, index=False)\n",
    "\n",
    "print(f\"\\n✅ С координатами: {len(main_records)} → {CSV_MAIN}\")\n",
    "print(f\"⚠️ Без координат : {len(missing_records)} → {CSV_MISSING}\")\n",
    "print(f\"📁 Фото сохранены в: {OUT_FOLDER} и {MISSING_FOLDER}\")\n",
    "print(f\"📝 Лог записан в: {LOG_FILE}\")\n",
    "print(\"🌍 Джиттер применён для повторяющихся координат\")\n",
    "print(\"\\n✅ Завершено. Результаты в photos.csv и missing_coords.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d657666-116e-471e-af10-017003a45925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67ebbf-b7c6-4998-9b56-f4ca452ce247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS\n",
    "\n",
    "# -- Add coordinates to missing_coords.csv and rename it into manual_coords.csv to include\n",
    "# remaining points\n",
    "# 1. Rename missing_coords into manual_coords\n",
    "# 2. Add coordinates (from manual_coords-Copy1.csv) or manually\n",
    "# 3. Check folder (should be photos)\n",
    "# 4. Run the script.\n",
    "# 5. Check the last lines of photos.csv to see if file names correspond to the ones in missing_coords/\n",
    "# 6. Move all files from missing_coords/ into photos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14a313-569a-4035-a3d8-ac6d48841336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "CSV_MAIN = \"csv/photos.csv\"\n",
    "CSV_EXTRA = \"csv/manual_coords.csv\"\n",
    "CSV_INVALID = \"csv/manual_invalid.csv\"\n",
    "LOG_FILE = \"csv/merge_log.txt\"\n",
    "\n",
    "def log(message):\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "    print(message)\n",
    "\n",
    "# === Проверка наличия файлов\n",
    "if not os.path.exists(CSV_MAIN):\n",
    "    raise FileNotFoundError(f\"Не найден основной файл: {CSV_MAIN}\")\n",
    "if not os.path.exists(CSV_EXTRA):\n",
    "    raise FileNotFoundError(f\"Не найден дополнительный файл: {CSV_EXTRA}\")\n",
    "\n",
    "# === Загрузка CSV\n",
    "main_df = pd.read_csv(CSV_MAIN)\n",
    "extra_df = pd.read_csv(CSV_EXTRA)\n",
    "\n",
    "# === Проверка структуры\n",
    "if set(main_df.columns) != set(extra_df.columns):\n",
    "    raise ValueError(\"❌ Колонки не совпадают между CSV-файлами!\")\n",
    "\n",
    "# === Фильтрация координат\n",
    "initial_len = len(extra_df)\n",
    "invalid_rows = extra_df[\n",
    "    extra_df[\"latitude\"].isna() |\n",
    "    extra_df[\"longitude\"].isna() |\n",
    "    (extra_df[\"latitude\"] == 0.0) |\n",
    "    (extra_df[\"longitude\"] == 0.0) |\n",
    "    (extra_df[\"latitude\"] < -90) | (extra_df[\"latitude\"] > 90) |\n",
    "    (extra_df[\"longitude\"] < -180) | (extra_df[\"longitude\"] > 180)\n",
    "]\n",
    "valid_extra_df = extra_df.drop(invalid_rows.index)\n",
    "\n",
    "# === Сохранение отклонённых\n",
    "if not invalid_rows.empty:\n",
    "    invalid_rows.to_csv(CSV_INVALID, index=False)\n",
    "\n",
    "# === Лог\n",
    "log(\"📋 ЛОГ ОБЪЕДИНЕНИЯ\")\n",
    "log(f\"Исходных строк в manual_coords.csv: {initial_len}\")\n",
    "log(f\"Допустимых строк: {len(valid_extra_df)}\")\n",
    "log(f\"Отклонено строк: {len(invalid_rows)}\")\n",
    "\n",
    "# === Объединение\n",
    "combined_df = pd.concat([main_df, valid_extra_df])\n",
    "combined_df = combined_df.drop_duplicates(subset=[\"filename\"])\n",
    "\n",
    "# === Сохранение\n",
    "combined_df.to_csv(CSV_MAIN, index=False)\n",
    "log(f\"✅ Объединение завершено. Финальное количество строк: {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf7353-3b67-4d0a-a1bc-a8a2b9d37e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Script deletes all files in Google Drive/Photos\n",
    "# --- Script uploads all files from photos/ to Google/Photos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f91472c-e053-47bb-9872-ff7de0262911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=849244129200-hdfqohk1rs46hjekajgu7pa4jqrn9sqj.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "🧹 Очистка папки на Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Удаление файлов: 100%|██████████| 1460/1460 [13:38<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Папка очищена.\n",
      "⬆️  Загрузка новых файлов в Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка файлов: 100%|██████████| 2431/2431 [3:10:57<00:00,  4.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Загрузка завершена.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === Авторизация в Google Drive\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# === ID целевой папки на Google Drive\n",
    "FOLDER_ID = '1em81MElkxnaue5r92e9hPGezgOuw4nRL'\n",
    "LOCAL_PHOTOS_FOLDER = 'photos/'\n",
    "\n",
    "# === Очистка папки на Google Drive\n",
    "print(\"🧹 Очистка папки на Google Drive...\")\n",
    "file_list = drive.ListFile({\n",
    "    'q': f\"'{FOLDER_ID}' in parents and trashed=false\"\n",
    "}).GetList()\n",
    "\n",
    "for f in tqdm(file_list, desc=\"Удаление файлов\"):\n",
    "    f.Delete()\n",
    "\n",
    "print(\"✅ Папка очищена.\")\n",
    "\n",
    "# === Загрузка новых файлов из локальной папки\n",
    "print(\"⬆️  Загрузка новых файлов в Google Drive...\")\n",
    "local_files = [f for f in os.listdir(LOCAL_PHOTOS_FOLDER) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "for fname in tqdm(local_files, desc=\"Загрузка файлов\"):\n",
    "    file_path = os.path.join(LOCAL_PHOTOS_FOLDER, fname)\n",
    "    gfile = drive.CreateFile({\n",
    "        'title': fname,\n",
    "        'parents': [{'id': FOLDER_ID}]\n",
    "    })\n",
    "    gfile.SetContentFile(file_path)\n",
    "    gfile.Upload()\n",
    "\n",
    "print(\"✅ Загрузка завершена.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcabf53-b8cd-4e8c-a399-7049600d3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Getting descriptions from Google photos via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe6e346e-9f1e-4b1c-80cb-16f542baa755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=849244129200-hdfqohk1rs46hjekajgu7pa4jqrn9sqj.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A60354%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fphotoslibrary.readonly&state=o3otxIUEcijTRIyPvoxZqfeQARifsC&access_type=offline\n",
      "🔍 Поиск альбомов в Google Photos...\n",
      "✅ Найдены альбомы: ['PhotoMap 2022-2025', 'PhotoMap 2019-2021', 'PhotoMap 2017-2019', 'PhotoMap 2014-2016', 'PhotoMap 2010-2013', 'PhotoMap 08-09']\n",
      "\n",
      "📂 Альбом: PhotoMap 2022-2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка из PhotoMap 2022-2025: 653фото [00:07, 87.67фото/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Альбом: PhotoMap 2019-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка из PhotoMap 2019-2021: 784фото [00:07, 101.69фото/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Альбом: PhotoMap 2017-2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка из PhotoMap 2017-2019: 249фото [00:02, 96.07фото/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Альбом: PhotoMap 2014-2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка из PhotoMap 2014-2016: 381фото [00:03, 98.38фото/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Альбом: PhotoMap 2010-2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка из PhotoMap 2010-2013: 257фото [00:03, 83.82фото/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Альбом: PhotoMap 08-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка из PhotoMap 08-09: 109фото [00:01, 72.67фото/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Все данные успешно записаны в csv/photos_descriptions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build_from_document\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Настройки ===\n",
    "SCOPES = ['https://www.googleapis.com/auth/photoslibrary.readonly']\n",
    "OUTPUT_CSV = 'csv/photos_descriptions.csv'\n",
    "ALBUM_NAMES = [\"PhotoMap 2022-2025\", \"PhotoMap 2019-2021\", \"PhotoMap 2017-2019\", \"PhotoMap 2014-2016\", \"PhotoMap 2010-2013\", \"PhotoMap 08-09\"]\n",
    "\n",
    "# === Аутентификация ===\n",
    "flow = InstalledAppFlow.from_client_secrets_file(\n",
    "    'client_secrets.json', SCOPES\n",
    ")\n",
    "credentials = flow.run_local_server(port=0)\n",
    "\n",
    "# Чтение локального discovery файла\n",
    "with open(\"photoslibrary_v1_discovery.json\", \"r\") as f:\n",
    "    discovery_doc = f.read()\n",
    "\n",
    "# Создание сервиса\n",
    "service = build_from_document(discovery_doc, credentials=credentials)\n",
    "\n",
    "# === Поиск нужных альбомов ===\n",
    "print(\"🔍 Поиск альбомов в Google Photos...\")\n",
    "albums = []\n",
    "nextPageToken = None\n",
    "\n",
    "while True:\n",
    "    response = service.albums().list(pageSize=50, pageToken=nextPageToken).execute()\n",
    "    albums.extend(response.get('albums', []))\n",
    "    nextPageToken = response.get('nextPageToken')\n",
    "    if not nextPageToken:\n",
    "        break\n",
    "\n",
    "target_albums = {album['title']: album['id'] for album in albums if album['title'] in ALBUM_NAMES}\n",
    "\n",
    "# === Проверка найденных альбомов ===\n",
    "if not target_albums:\n",
    "    print(\"❌ Не найдены указанные альбомы в Google Photos\")\n",
    "else:\n",
    "    print(f\"✅ Найдены альбомы: {list(target_albums.keys())}\")\n",
    "\n",
    "# === Запись в CSV ===\n",
    "os.makedirs('csv', exist_ok=True)\n",
    "with open(OUTPUT_CSV, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['file_id', 'description'])\n",
    "\n",
    "    for album_name, album_id in target_albums.items():\n",
    "        print(f\"\\n📂 Альбом: {album_name}\")\n",
    "        nextPageToken = None\n",
    "        \n",
    "        with tqdm(desc=f\"Загрузка из {album_name}\", unit=\"фото\", leave=True) as pbar:\n",
    "            while True:\n",
    "                results = service.mediaItems().search(\n",
    "                    body={\"albumId\": album_id, \"pageSize\": 100, \"pageToken\": nextPageToken}\n",
    "                ).execute()\n",
    "\n",
    "                items = results.get('mediaItems', [])\n",
    "                nextPageToken = results.get('nextPageToken')\n",
    "\n",
    "                if not items:\n",
    "                    break\n",
    "\n",
    "                for item in items:\n",
    "                    file_id = item.get('id', 'No ID')\n",
    "                    description = item.get('description', 'No Description')\n",
    "                    writer.writerow([file_id, description])\n",
    "\n",
    "                # === Динамическое обновление прогресса ===\n",
    "                pbar.update(len(items))\n",
    "\n",
    "                if not nextPageToken:\n",
    "                    break\n",
    "\n",
    "    print(f\"\\n✅ Все данные успешно записаны в {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441939e-2c18-4688-b1db-a6e001c01204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
